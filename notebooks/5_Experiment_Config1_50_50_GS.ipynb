{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b52d66",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'lassification_report' from 'sklearn.metrics' (d:\\Pemograman Python\\Pengembangan Model MLP\\venv\\Lib\\site-packages\\sklearn\\metrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneural_network\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MLPClassifier\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, mean_squared_error, precision_recall_fscore_support, confusion_matrix, lassification_report\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'lassification_report' from 'sklearn.metrics' (d:\\Pemograman Python\\Pengembangan Model MLP\\venv\\Lib\\site-packages\\sklearn\\metrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, precision_recall_fscore_support, confusion_matrix, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d976ef28",
   "metadata": {},
   "source": [
    "## Adam Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c37f33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading Data...\n",
      "ðŸš€ MEMULAI 156 KOMBINASI EKSPERIMEN (FULL METRICS)...\n",
      "============================================================\n",
      "âœ… Exp 1: logistic | LR 0.04 | Acc: 98.68%\n",
      "âœ… Exp 2: logistic | LR 0.08 | Acc: 98.91%\n",
      "âœ… Exp 3: logistic | LR 0.06 | Acc: 98.67%\n",
      "âœ… Exp 4: logistic | LR 0.005 | Acc: 99.47%\n",
      "âœ… Exp 5: logistic | LR 0.009 | Acc: 98.87%\n",
      "âœ… Exp 6: logistic | LR 0.007 | Acc: 99.68%\n",
      "âœ… Exp 7: logistic | LR 0.2 | Acc: 97.68%\n",
      "âœ… Exp 8: logistic | LR 0.6 | Acc: 93.13%\n",
      "âœ… Exp 9: logistic | LR 0.012 | Acc: 99.33%\n",
      "âœ… Exp 10: logistic | LR 0.01 | Acc: 99.53%\n",
      "âœ… Exp 11: logistic | LR 0.015 | Acc: 99.37%\n",
      "âœ… Exp 12: logistic | LR 0.018 | Acc: 99.48%\n",
      "âœ… Exp 13: logistic | LR 0.0111 | Acc: 99.44%\n",
      "âœ… Exp 14: relu | LR 0.04 | Acc: 99.03%\n",
      "âœ… Exp 15: relu | LR 0.08 | Acc: 99.31%\n",
      "âœ… Exp 16: relu | LR 0.06 | Acc: 98.40%\n",
      "âœ… Exp 17: relu | LR 0.005 | Acc: 99.09%\n",
      "âœ… Exp 18: relu | LR 0.009 | Acc: 99.23%\n",
      "âœ… Exp 19: relu | LR 0.007 | Acc: 99.67%\n",
      "âœ… Exp 20: relu | LR 0.2 | Acc: 99.03%\n",
      "âœ… Exp 21: relu | LR 0.6 | Acc: 77.29%\n",
      "âœ… Exp 22: relu | LR 0.012 | Acc: 99.43%\n",
      "âœ… Exp 23: relu | LR 0.01 | Acc: 98.72%\n",
      "âœ… Exp 24: relu | LR 0.015 | Acc: 98.88%\n",
      "âœ… Exp 25: relu | LR 0.018 | Acc: 99.15%\n",
      "âœ… Exp 26: relu | LR 0.0111 | Acc: 99.00%\n",
      "âœ… Exp 27: tanh | LR 0.04 | Acc: 97.36%\n",
      "âœ… Exp 28: tanh | LR 0.08 | Acc: 98.05%\n",
      "âœ… Exp 29: tanh | LR 0.06 | Acc: 98.07%\n",
      "âœ… Exp 30: tanh | LR 0.005 | Acc: 98.88%\n",
      "âœ… Exp 31: tanh | LR 0.009 | Acc: 99.15%\n",
      "âœ… Exp 32: tanh | LR 0.007 | Acc: 98.79%\n",
      "âœ… Exp 33: tanh | LR 0.2 | Acc: 95.85%\n",
      "âœ… Exp 34: tanh | LR 0.6 | Acc: 90.37%\n",
      "âœ… Exp 35: tanh | LR 0.012 | Acc: 99.29%\n",
      "âœ… Exp 36: tanh | LR 0.01 | Acc: 99.32%\n",
      "âœ… Exp 37: tanh | LR 0.015 | Acc: 99.64%\n",
      "âœ… Exp 38: tanh | LR 0.018 | Acc: 99.27%\n",
      "âœ… Exp 39: tanh | LR 0.0111 | Acc: 99.44%\n",
      "âœ… Exp 40: logistic | LR 0.04 | Acc: 98.92%\n",
      "âœ… Exp 41: logistic | LR 0.08 | Acc: 99.00%\n",
      "âœ… Exp 42: logistic | LR 0.06 | Acc: 99.33%\n",
      "âœ… Exp 43: logistic | LR 0.005 | Acc: 99.32%\n",
      "âœ… Exp 44: logistic | LR 0.009 | Acc: 99.15%\n",
      "âœ… Exp 45: logistic | LR 0.007 | Acc: 99.37%\n",
      "âœ… Exp 46: logistic | LR 0.2 | Acc: 50.00%\n",
      "âœ… Exp 47: logistic | LR 0.6 | Acc: 50.00%\n",
      "âœ… Exp 48: logistic | LR 0.012 | Acc: 99.31%\n",
      "âœ… Exp 49: logistic | LR 0.01 | Acc: 99.23%\n",
      "âœ… Exp 50: logistic | LR 0.015 | Acc: 99.25%\n",
      "âœ… Exp 51: logistic | LR 0.018 | Acc: 99.57%\n",
      "âœ… Exp 52: logistic | LR 0.0111 | Acc: 99.35%\n",
      "âœ… Exp 53: relu | LR 0.04 | Acc: 99.27%\n",
      "âœ… Exp 54: relu | LR 0.08 | Acc: 98.56%\n",
      "âœ… Exp 55: relu | LR 0.06 | Acc: 99.07%\n",
      "âœ… Exp 56: relu | LR 0.005 | Acc: 99.41%\n",
      "âœ… Exp 57: relu | LR 0.009 | Acc: 99.24%\n",
      "âœ… Exp 58: relu | LR 0.007 | Acc: 99.28%\n",
      "âœ… Exp 59: relu | LR 0.2 | Acc: 99.19%\n",
      "âœ… Exp 60: relu | LR 0.6 | Acc: 50.01%\n",
      "âœ… Exp 61: relu | LR 0.012 | Acc: 99.25%\n",
      "âœ… Exp 62: relu | LR 0.01 | Acc: 99.12%\n",
      "âœ… Exp 63: relu | LR 0.015 | Acc: 98.96%\n",
      "âœ… Exp 64: relu | LR 0.018 | Acc: 99.29%\n",
      "âœ… Exp 65: relu | LR 0.0111 | Acc: 99.07%\n",
      "âœ… Exp 66: tanh | LR 0.04 | Acc: 99.07%\n",
      "âœ… Exp 67: tanh | LR 0.08 | Acc: 97.41%\n",
      "âœ… Exp 68: tanh | LR 0.06 | Acc: 98.29%\n",
      "âœ… Exp 69: tanh | LR 0.005 | Acc: 99.39%\n",
      "âœ… Exp 70: tanh | LR 0.009 | Acc: 98.96%\n",
      "âœ… Exp 71: tanh | LR 0.007 | Acc: 99.37%\n",
      "âœ… Exp 72: tanh | LR 0.2 | Acc: 93.63%\n",
      "âœ… Exp 73: tanh | LR 0.6 | Acc: 80.41%\n",
      "âœ… Exp 74: tanh | LR 0.012 | Acc: 99.07%\n",
      "âœ… Exp 75: tanh | LR 0.01 | Acc: 98.99%\n",
      "âœ… Exp 76: tanh | LR 0.015 | Acc: 99.47%\n",
      "âœ… Exp 77: tanh | LR 0.018 | Acc: 99.24%\n",
      "âœ… Exp 78: tanh | LR 0.0111 | Acc: 99.03%\n",
      "âœ… Exp 79: logistic | LR 0.04 | Acc: 99.13%\n",
      "âœ… Exp 80: logistic | LR 0.08 | Acc: 97.05%\n",
      "âœ… Exp 81: logistic | LR 0.06 | Acc: 98.55%\n",
      "âœ… Exp 82: logistic | LR 0.005 | Acc: 99.45%\n",
      "âœ… Exp 83: logistic | LR 0.009 | Acc: 99.23%\n",
      "âœ… Exp 84: logistic | LR 0.007 | Acc: 99.31%\n",
      "âœ… Exp 85: logistic | LR 0.2 | Acc: 50.00%\n",
      "âœ… Exp 86: logistic | LR 0.6 | Acc: 50.00%\n",
      "âœ… Exp 87: logistic | LR 0.012 | Acc: 99.31%\n",
      "âœ… Exp 88: logistic | LR 0.01 | Acc: 99.15%\n",
      "âœ… Exp 89: logistic | LR 0.015 | Acc: 99.00%\n",
      "âœ… Exp 90: logistic | LR 0.018 | Acc: 99.55%\n",
      "âœ… Exp 91: logistic | LR 0.0111 | Acc: 99.11%\n",
      "âœ… Exp 92: relu | LR 0.04 | Acc: 98.36%\n",
      "âœ… Exp 93: relu | LR 0.08 | Acc: 99.28%\n",
      "âœ… Exp 94: relu | LR 0.06 | Acc: 97.85%\n",
      "âœ… Exp 95: relu | LR 0.005 | Acc: 99.67%\n",
      "âœ… Exp 96: relu | LR 0.009 | Acc: 98.93%\n",
      "âœ… Exp 97: relu | LR 0.007 | Acc: 99.33%\n",
      "âœ… Exp 98: relu | LR 0.2 | Acc: 98.72%\n",
      "âœ… Exp 99: relu | LR 0.6 | Acc: 50.00%\n",
      "âœ… Exp 100: relu | LR 0.012 | Acc: 99.03%\n",
      "âœ… Exp 101: relu | LR 0.01 | Acc: 98.40%\n",
      "âœ… Exp 102: relu | LR 0.015 | Acc: 99.27%\n",
      "âœ… Exp 103: relu | LR 0.018 | Acc: 98.55%\n",
      "âœ… Exp 104: relu | LR 0.0111 | Acc: 99.29%\n",
      "âœ… Exp 105: tanh | LR 0.04 | Acc: 97.80%\n",
      "âœ… Exp 106: tanh | LR 0.08 | Acc: 96.23%\n",
      "âœ… Exp 107: tanh | LR 0.06 | Acc: 97.01%\n",
      "âœ… Exp 108: tanh | LR 0.005 | Acc: 99.11%\n",
      "âœ… Exp 109: tanh | LR 0.009 | Acc: 98.28%\n",
      "âœ… Exp 110: tanh | LR 0.007 | Acc: 99.20%\n",
      "âœ… Exp 111: tanh | LR 0.2 | Acc: 85.04%\n",
      "âœ… Exp 112: tanh | LR 0.6 | Acc: 68.84%\n",
      "âœ… Exp 113: tanh | LR 0.012 | Acc: 98.95%\n",
      "âœ… Exp 114: tanh | LR 0.01 | Acc: 98.59%\n",
      "âœ… Exp 115: tanh | LR 0.015 | Acc: 98.81%\n",
      "âœ… Exp 116: tanh | LR 0.018 | Acc: 98.83%\n",
      "âœ… Exp 117: tanh | LR 0.0111 | Acc: 98.64%\n",
      "âœ… Exp 118: logistic | LR 0.04 | Acc: 99.21%\n",
      "âœ… Exp 119: logistic | LR 0.08 | Acc: 50.00%\n",
      "âœ… Exp 120: logistic | LR 0.06 | Acc: 50.00%\n",
      "âœ… Exp 121: logistic | LR 0.005 | Acc: 99.64%\n",
      "âœ… Exp 122: logistic | LR 0.009 | Acc: 99.33%\n",
      "âœ… Exp 123: logistic | LR 0.007 | Acc: 99.52%\n",
      "âœ… Exp 124: logistic | LR 0.2 | Acc: 50.00%\n",
      "âœ… Exp 125: logistic | LR 0.6 | Acc: 50.00%\n",
      "âœ… Exp 126: logistic | LR 0.012 | Acc: 98.83%\n",
      "âœ… Exp 127: logistic | LR 0.01 | Acc: 99.68%\n",
      "âœ… Exp 128: logistic | LR 0.015 | Acc: 99.05%\n",
      "âœ… Exp 129: logistic | LR 0.018 | Acc: 99.21%\n",
      "âœ… Exp 130: logistic | LR 0.0111 | Acc: 98.96%\n",
      "âœ… Exp 131: relu | LR 0.04 | Acc: 99.13%\n",
      "âœ… Exp 132: relu | LR 0.08 | Acc: 98.93%\n",
      "âœ… Exp 133: relu | LR 0.06 | Acc: 98.99%\n",
      "âœ… Exp 134: relu | LR 0.005 | Acc: 99.40%\n",
      "âœ… Exp 135: relu | LR 0.009 | Acc: 98.80%\n",
      "âœ… Exp 136: relu | LR 0.007 | Acc: 98.77%\n",
      "âœ… Exp 137: relu | LR 0.2 | Acc: 50.00%\n",
      "âœ… Exp 138: relu | LR 0.6 | Acc: 50.00%\n",
      "âœ… Exp 139: relu | LR 0.012 | Acc: 99.63%\n",
      "âœ… Exp 140: relu | LR 0.01 | Acc: 98.87%\n",
      "âœ… Exp 141: relu | LR 0.015 | Acc: 98.85%\n",
      "âœ… Exp 142: relu | LR 0.018 | Acc: 98.63%\n",
      "âœ… Exp 143: relu | LR 0.0111 | Acc: 99.44%\n",
      "âœ… Exp 144: tanh | LR 0.04 | Acc: 95.99%\n",
      "âœ… Exp 145: tanh | LR 0.08 | Acc: 94.79%\n",
      "âœ… Exp 146: tanh | LR 0.06 | Acc: 96.19%\n",
      "âœ… Exp 147: tanh | LR 0.005 | Acc: 99.47%\n",
      "âœ… Exp 148: tanh | LR 0.009 | Acc: 97.32%\n",
      "âœ… Exp 149: tanh | LR 0.007 | Acc: 99.25%\n",
      "âœ… Exp 150: tanh | LR 0.2 | Acc: 86.12%\n",
      "âœ… Exp 151: tanh | LR 0.6 | Acc: 61.99%\n",
      "âœ… Exp 152: tanh | LR 0.012 | Acc: 98.84%\n",
      "âœ… Exp 153: tanh | LR 0.01 | Acc: 98.41%\n",
      "âœ… Exp 154: tanh | LR 0.015 | Acc: 98.67%\n",
      "âœ… Exp 155: tanh | LR 0.018 | Acc: 99.05%\n",
      "âœ… Exp 156: tanh | LR 0.0111 | Acc: 98.57%\n",
      "\n",
      "============================================================\n",
      "ðŸŽ‰ SELESAI! File tersimpan sebagai: Hasil_GridSearch_Massive_Lengkap.csv\n",
      "Sekarang kolom Precision dan Recall sudah lengkap.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. PERSIAPAN DATA\n",
    "# ==========================================\n",
    "print(\"ðŸ“‚ Loading Data...\")\n",
    "df = pd.read_csv('../data/processed_attrition_data.csv') \n",
    "X = df.drop(columns=['Attrition_Risk_Level'])\n",
    "y = df['Attrition_Risk_Level']\n",
    "\n",
    "# Config-1: Split 50:50 (Bisa diganti nanti)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# ==========================================\n",
    "# 2. VARIABEL EKSPERIMEN (GRID SEARCH)\n",
    "# ==========================================\n",
    "list_lr = [0.04, 0.08, 0.06, 0.005, 0.009, 0.007, 0.2, 0.6, 0.012, 0.010, 0.015, 0.018, 0.0111]\n",
    "list_activation = ['logistic', 'relu', 'tanh']\n",
    "list_architecture = [(100, 50), (32, 64, 16), (128, 64, 32, 16), (256, 128, 64, 32, 16)]\n",
    "\n",
    "results = []\n",
    "counter = 1\n",
    "total_exp = len(list_lr) * len(list_activation) * len(list_architecture)\n",
    "\n",
    "print(f\"ðŸš€ MEMULAI {total_exp} KOMBINASI EKSPERIMEN (FULL METRICS)...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ==========================================\n",
    "# 3. TRIPLE LOOPING\n",
    "# ==========================================\n",
    "for arch in list_architecture:\n",
    "    for act in list_activation:\n",
    "        for LR in list_lr:\n",
    "            \n",
    "            # Definisi Model\n",
    "            mlp = MLPClassifier(\n",
    "                hidden_layer_sizes=arch,\n",
    "                activation=act,\n",
    "                solver='adam',\n",
    "                learning_rate_init=LR,\n",
    "                momentum=0.8,\n",
    "                max_iter=375,\n",
    "                random_state=52,\n",
    "                early_stopping=True,\n",
    "                validation_fraction=0.1,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Training\n",
    "            mlp.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # Evaluasi\n",
    "            y_train_pred = mlp.predict(X_train_scaled)\n",
    "            mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "            acc_train = accuracy_score(y_train, y_train_pred)\n",
    "            \n",
    "            # Hitung Detail Per Kelas\n",
    "            precision, recall, f1, support = precision_recall_fscore_support(\n",
    "                y_train, y_train_pred, labels=[0, 1, 2], zero_division=0\n",
    "            )\n",
    "            \n",
    "            # Simpan Data LENGKAP\n",
    "            row = {\n",
    "                \"No\": counter,\n",
    "                \"Split\": \"50:50\",\n",
    "                \"Arsitektur\": str(arch),\n",
    "                \"Activation\": act,\n",
    "                \"Learning Rate\": LR,\n",
    "                \"Epoch\": mlp.n_iter_,\n",
    "                \"Loss (MSE)\": round(mse_train, 5),\n",
    "                \"Acc Train\": round(acc_train, 4),\n",
    "                \n",
    "                # --- Precision ---\n",
    "                \"Train Precision 0\": round(precision[0], 4),\n",
    "                \"Train Precision 1\": round(precision[1], 4),\n",
    "                \"Train Precision 2\": round(precision[2], 4),\n",
    "                \n",
    "                # --- Recall ---\n",
    "                \"Train Recall 0\": round(recall[0], 4),\n",
    "                \"Train Recall 1\": round(recall[1], 4),\n",
    "                \"Train Recall 2\": round(recall[2], 4),\n",
    "                \n",
    "                # --- F1 Score ---\n",
    "                \"Train F1 0\": round(f1[0], 4),\n",
    "                \"Train F1 1\": round(f1[1], 4),\n",
    "                \"Train F1 2\": round(f1[2], 4),\n",
    "                \n",
    "                # --- Support (Optional) ---\n",
    "                \"Support 0\": support[0],\n",
    "                \"Support 1\": support[1],\n",
    "                \"Support 2\": support[2]\n",
    "            }\n",
    "            results.append(row)\n",
    "            print(f\"âœ… Exp {counter}: {act} | LR {LR} | Acc: {acc_train:.2%}\")\n",
    "            counter += 1\n",
    "\n",
    "# ==========================================\n",
    "# 4. EXPORT\n",
    "# ==========================================\n",
    "df_results = pd.DataFrame(results)\n",
    "nama_file = \"Hasil_GridSearch_Massive_Lengkap.csv\"\n",
    "df_results.to_csv(nama_file, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ðŸŽ‰ SELESAI! File tersimpan sebagai: {nama_file}\")\n",
    "print(\"Sekarang kolom Precision dan Recall sudah lengkap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd2d6b7",
   "metadata": {},
   "source": [
    "## SGD Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0b4377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading Data...\n",
      "ðŸš€ MEMULAI 156 EKSPERIMEN SGD (FULL METRICS)...\n",
      "============================================================\n",
      "âœ… Exp 1: SGD | logistic | LR 0.04 | Acc: 99.31%\n",
      "âœ… Exp 2: SGD | logistic | LR 0.08 | Acc: 99.09%\n",
      "âœ… Exp 3: SGD | logistic | LR 0.06 | Acc: 99.41%\n",
      "âœ… Exp 4: SGD | logistic | LR 0.005 | Acc: 50.00%\n",
      "âœ… Exp 5: SGD | logistic | LR 0.009 | Acc: 50.00%\n",
      "âœ… Exp 6: SGD | logistic | LR 0.007 | Acc: 50.00%\n",
      "âœ… Exp 7: SGD | logistic | LR 0.2 | Acc: 99.49%\n",
      "âœ… Exp 8: SGD | logistic | LR 0.6 | Acc: 99.12%\n",
      "âœ… Exp 9: SGD | logistic | LR 0.012 | Acc: 50.00%\n",
      "âœ… Exp 10: SGD | logistic | LR 0.01 | Acc: 50.00%\n",
      "âœ… Exp 11: SGD | logistic | LR 0.015 | Acc: 99.07%\n",
      "âœ… Exp 12: SGD | logistic | LR 0.018 | Acc: 99.20%\n",
      "âœ… Exp 13: SGD | logistic | LR 0.0111 | Acc: 50.00%\n",
      "âœ… Exp 14: SGD | relu | LR 0.04 | Acc: 99.39%\n",
      "âœ… Exp 15: SGD | relu | LR 0.08 | Acc: 99.69%\n",
      "âœ… Exp 16: SGD | relu | LR 0.06 | Acc: 99.45%\n",
      "âœ… Exp 17: SGD | relu | LR 0.005 | Acc: 98.96%\n",
      "âœ… Exp 18: SGD | relu | LR 0.009 | Acc: 99.33%\n",
      "âœ… Exp 19: SGD | relu | LR 0.007 | Acc: 99.33%\n",
      "âœ… Exp 20: SGD | relu | LR 0.2 | Acc: 99.33%\n",
      "âœ… Exp 21: SGD | relu | LR 0.6 | Acc: 99.13%\n",
      "âœ… Exp 22: SGD | relu | LR 0.012 | Acc: 99.12%\n",
      "âœ… Exp 23: SGD | relu | LR 0.01 | Acc: 98.81%\n",
      "âœ… Exp 24: SGD | relu | LR 0.015 | Acc: 99.16%\n",
      "âœ… Exp 25: SGD | relu | LR 0.018 | Acc: 99.19%\n",
      "âœ… Exp 26: SGD | relu | LR 0.0111 | Acc: 99.03%\n",
      "âœ… Exp 27: SGD | tanh | LR 0.04 | Acc: 99.25%\n",
      "âœ… Exp 28: SGD | tanh | LR 0.08 | Acc: 99.52%\n",
      "âœ… Exp 29: SGD | tanh | LR 0.06 | Acc: 99.48%\n",
      "âœ… Exp 30: SGD | tanh | LR 0.005 | Acc: 98.76%\n",
      "âœ… Exp 31: SGD | tanh | LR 0.009 | Acc: 99.56%\n",
      "âœ… Exp 32: SGD | tanh | LR 0.007 | Acc: 98.83%\n",
      "âœ… Exp 33: SGD | tanh | LR 0.2 | Acc: 99.37%\n",
      "âœ… Exp 34: SGD | tanh | LR 0.6 | Acc: 98.79%\n",
      "âœ… Exp 35: SGD | tanh | LR 0.012 | Acc: 99.51%\n",
      "âœ… Exp 36: SGD | tanh | LR 0.01 | Acc: 99.41%\n",
      "âœ… Exp 37: SGD | tanh | LR 0.015 | Acc: 99.35%\n",
      "âœ… Exp 38: SGD | tanh | LR 0.018 | Acc: 99.36%\n",
      "âœ… Exp 39: SGD | tanh | LR 0.0111 | Acc: 99.27%\n",
      "âœ… Exp 40: SGD | logistic | LR 0.04 | Acc: 50.00%\n",
      "âœ… Exp 41: SGD | logistic | LR 0.08 | Acc: 50.00%\n",
      "âœ… Exp 42: SGD | logistic | LR 0.06 | Acc: 50.00%\n",
      "âœ… Exp 43: SGD | logistic | LR 0.005 | Acc: 50.00%\n",
      "âœ… Exp 44: SGD | logistic | LR 0.009 | Acc: 50.00%\n",
      "âœ… Exp 45: SGD | logistic | LR 0.007 | Acc: 50.00%\n",
      "âœ… Exp 46: SGD | logistic | LR 0.2 | Acc: 99.05%\n",
      "âœ… Exp 47: SGD | logistic | LR 0.6 | Acc: 99.40%\n",
      "âœ… Exp 48: SGD | logistic | LR 0.012 | Acc: 50.00%\n",
      "âœ… Exp 49: SGD | logistic | LR 0.01 | Acc: 50.00%\n",
      "âœ… Exp 50: SGD | logistic | LR 0.015 | Acc: 50.00%\n",
      "âœ… Exp 51: SGD | logistic | LR 0.018 | Acc: 50.00%\n",
      "âœ… Exp 52: SGD | logistic | LR 0.0111 | Acc: 50.00%\n",
      "âœ… Exp 53: SGD | relu | LR 0.04 | Acc: 99.28%\n",
      "âœ… Exp 54: SGD | relu | LR 0.08 | Acc: 98.96%\n",
      "âœ… Exp 55: SGD | relu | LR 0.06 | Acc: 99.05%\n",
      "âœ… Exp 56: SGD | relu | LR 0.005 | Acc: 98.77%\n",
      "âœ… Exp 57: SGD | relu | LR 0.009 | Acc: 98.41%\n",
      "âœ… Exp 58: SGD | relu | LR 0.007 | Acc: 98.21%\n",
      "âœ… Exp 59: SGD | relu | LR 0.2 | Acc: 99.15%\n",
      "âœ… Exp 60: SGD | relu | LR 0.6 | Acc: 99.33%\n",
      "âœ… Exp 61: SGD | relu | LR 0.012 | Acc: 98.72%\n",
      "âœ… Exp 62: SGD | relu | LR 0.01 | Acc: 98.59%\n",
      "âœ… Exp 63: SGD | relu | LR 0.015 | Acc: 99.39%\n",
      "âœ… Exp 64: SGD | relu | LR 0.018 | Acc: 98.91%\n",
      "âœ… Exp 65: SGD | relu | LR 0.0111 | Acc: 98.57%\n",
      "âœ… Exp 66: SGD | tanh | LR 0.04 | Acc: 99.19%\n",
      "âœ… Exp 67: SGD | tanh | LR 0.08 | Acc: 99.37%\n",
      "âœ… Exp 68: SGD | tanh | LR 0.06 | Acc: 99.40%\n",
      "âœ… Exp 69: SGD | tanh | LR 0.005 | Acc: 99.19%\n",
      "âœ… Exp 70: SGD | tanh | LR 0.009 | Acc: 99.52%\n",
      "âœ… Exp 71: SGD | tanh | LR 0.007 | Acc: 99.51%\n",
      "âœ… Exp 72: SGD | tanh | LR 0.2 | Acc: 99.12%\n",
      "âœ… Exp 73: SGD | tanh | LR 0.6 | Acc: 99.09%\n",
      "âœ… Exp 74: SGD | tanh | LR 0.012 | Acc: 99.45%\n",
      "âœ… Exp 75: SGD | tanh | LR 0.01 | Acc: 99.41%\n",
      "âœ… Exp 76: SGD | tanh | LR 0.015 | Acc: 99.33%\n",
      "âœ… Exp 77: SGD | tanh | LR 0.018 | Acc: 99.33%\n",
      "âœ… Exp 78: SGD | tanh | LR 0.0111 | Acc: 99.43%\n",
      "âœ… Exp 79: SGD | logistic | LR 0.04 | Acc: 50.00%\n",
      "âœ… Exp 80: SGD | logistic | LR 0.08 | Acc: 50.00%\n",
      "âœ… Exp 81: SGD | logistic | LR 0.06 | Acc: 50.00%\n",
      "âœ… Exp 82: SGD | logistic | LR 0.005 | Acc: 50.00%\n",
      "âœ… Exp 83: SGD | logistic | LR 0.009 | Acc: 50.00%\n",
      "âœ… Exp 84: SGD | logistic | LR 0.007 | Acc: 50.00%\n",
      "âœ… Exp 85: SGD | logistic | LR 0.2 | Acc: 50.00%\n",
      "âœ… Exp 86: SGD | logistic | LR 0.6 | Acc: 99.48%\n",
      "âœ… Exp 87: SGD | logistic | LR 0.012 | Acc: 50.00%\n",
      "âœ… Exp 88: SGD | logistic | LR 0.01 | Acc: 50.00%\n",
      "âœ… Exp 89: SGD | logistic | LR 0.015 | Acc: 50.00%\n",
      "âœ… Exp 90: SGD | logistic | LR 0.018 | Acc: 50.00%\n",
      "âœ… Exp 91: SGD | logistic | LR 0.0111 | Acc: 50.00%\n",
      "âœ… Exp 92: SGD | relu | LR 0.04 | Acc: 99.47%\n",
      "âœ… Exp 93: SGD | relu | LR 0.08 | Acc: 99.39%\n",
      "âœ… Exp 94: SGD | relu | LR 0.06 | Acc: 99.12%\n",
      "âœ… Exp 95: SGD | relu | LR 0.005 | Acc: 99.57%\n",
      "âœ… Exp 96: SGD | relu | LR 0.009 | Acc: 98.97%\n",
      "âœ… Exp 97: SGD | relu | LR 0.007 | Acc: 99.73%\n",
      "âœ… Exp 98: SGD | relu | LR 0.2 | Acc: 98.75%\n",
      "âœ… Exp 99: SGD | relu | LR 0.6 | Acc: 99.41%\n",
      "âœ… Exp 100: SGD | relu | LR 0.012 | Acc: 99.65%\n",
      "âœ… Exp 101: SGD | relu | LR 0.01 | Acc: 99.77%\n",
      "âœ… Exp 102: SGD | relu | LR 0.015 | Acc: 99.59%\n",
      "âœ… Exp 103: SGD | relu | LR 0.018 | Acc: 99.79%\n",
      "âœ… Exp 104: SGD | relu | LR 0.0111 | Acc: 99.57%\n",
      "âœ… Exp 105: SGD | tanh | LR 0.04 | Acc: 98.88%\n",
      "âœ… Exp 106: SGD | tanh | LR 0.08 | Acc: 98.03%\n",
      "âœ… Exp 107: SGD | tanh | LR 0.06 | Acc: 98.40%\n",
      "âœ… Exp 108: SGD | tanh | LR 0.005 | Acc: 99.43%\n",
      "âœ… Exp 109: SGD | tanh | LR 0.009 | Acc: 99.17%\n",
      "âœ… Exp 110: SGD | tanh | LR 0.007 | Acc: 99.43%\n",
      "âœ… Exp 111: SGD | tanh | LR 0.2 | Acc: 98.56%\n",
      "âœ… Exp 112: SGD | tanh | LR 0.6 | Acc: 98.97%\n",
      "âœ… Exp 113: SGD | tanh | LR 0.012 | Acc: 99.25%\n",
      "âœ… Exp 114: SGD | tanh | LR 0.01 | Acc: 99.21%\n",
      "âœ… Exp 115: SGD | tanh | LR 0.015 | Acc: 99.17%\n",
      "âœ… Exp 116: SGD | tanh | LR 0.018 | Acc: 99.03%\n",
      "âœ… Exp 117: SGD | tanh | LR 0.0111 | Acc: 99.25%\n",
      "âœ… Exp 118: SGD | logistic | LR 0.04 | Acc: 50.00%\n",
      "âœ… Exp 119: SGD | logistic | LR 0.08 | Acc: 50.00%\n",
      "âœ… Exp 120: SGD | logistic | LR 0.06 | Acc: 50.00%\n",
      "âœ… Exp 121: SGD | logistic | LR 0.005 | Acc: 50.00%\n",
      "âœ… Exp 122: SGD | logistic | LR 0.009 | Acc: 50.00%\n",
      "âœ… Exp 123: SGD | logistic | LR 0.007 | Acc: 50.00%\n",
      "âœ… Exp 124: SGD | logistic | LR 0.2 | Acc: 50.00%\n",
      "âœ… Exp 125: SGD | logistic | LR 0.6 | Acc: 50.00%\n",
      "âœ… Exp 126: SGD | logistic | LR 0.012 | Acc: 50.00%\n",
      "âœ… Exp 127: SGD | logistic | LR 0.01 | Acc: 50.00%\n",
      "âœ… Exp 128: SGD | logistic | LR 0.015 | Acc: 50.00%\n",
      "âœ… Exp 129: SGD | logistic | LR 0.018 | Acc: 50.00%\n",
      "âœ… Exp 130: SGD | logistic | LR 0.0111 | Acc: 50.00%\n",
      "âœ… Exp 131: SGD | relu | LR 0.04 | Acc: 99.33%\n",
      "âœ… Exp 132: SGD | relu | LR 0.08 | Acc: 98.88%\n",
      "âœ… Exp 133: SGD | relu | LR 0.06 | Acc: 98.64%\n",
      "âœ… Exp 134: SGD | relu | LR 0.005 | Acc: 97.91%\n",
      "âœ… Exp 135: SGD | relu | LR 0.009 | Acc: 99.49%\n",
      "âœ… Exp 136: SGD | relu | LR 0.007 | Acc: 98.32%\n",
      "âœ… Exp 137: SGD | relu | LR 0.2 | Acc: 99.20%\n",
      "âœ… Exp 138: SGD | relu | LR 0.6 | Acc: 69.16%\n",
      "âœ… Exp 139: SGD | relu | LR 0.012 | Acc: 99.68%\n",
      "âœ… Exp 140: SGD | relu | LR 0.01 | Acc: 99.76%\n",
      "âœ… Exp 141: SGD | relu | LR 0.015 | Acc: 99.61%\n",
      "âœ… Exp 142: SGD | relu | LR 0.018 | Acc: 99.79%\n",
      "âœ… Exp 143: SGD | relu | LR 0.0111 | Acc: 98.09%\n",
      "âœ… Exp 144: SGD | tanh | LR 0.04 | Acc: 99.07%\n",
      "âœ… Exp 145: SGD | tanh | LR 0.08 | Acc: 99.19%\n",
      "âœ… Exp 146: SGD | tanh | LR 0.06 | Acc: 99.00%\n",
      "âœ… Exp 147: SGD | tanh | LR 0.005 | Acc: 99.17%\n",
      "âœ… Exp 148: SGD | tanh | LR 0.009 | Acc: 99.13%\n",
      "âœ… Exp 149: SGD | tanh | LR 0.007 | Acc: 99.32%\n",
      "âœ… Exp 150: SGD | tanh | LR 0.2 | Acc: 99.15%\n",
      "âœ… Exp 151: SGD | tanh | LR 0.6 | Acc: 98.69%\n",
      "âœ… Exp 152: SGD | tanh | LR 0.012 | Acc: 99.09%\n",
      "âœ… Exp 153: SGD | tanh | LR 0.01 | Acc: 99.61%\n",
      "âœ… Exp 154: SGD | tanh | LR 0.015 | Acc: 99.08%\n",
      "âœ… Exp 155: SGD | tanh | LR 0.018 | Acc: 98.97%\n",
      "âœ… Exp 156: SGD | tanh | LR 0.0111 | Acc: 99.12%\n",
      "\n",
      "============================================================\n",
      "ðŸŽ‰ SELESAI! File tersimpan sebagai: Hasil_GridSearch_SGD_Lengkap.csv\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. PERSIAPAN DATA\n",
    "# ==========================================\n",
    "print(\"ðŸ“‚ Loading Data...\")\n",
    "# Pastikan path file csv sesuai dengan lokasi di laptop kamu\n",
    "df = pd.read_csv('../data/processed_attrition_data.csv') \n",
    "X = df.drop(columns=['Attrition_Risk_Level'])\n",
    "y = df['Attrition_Risk_Level']\n",
    "\n",
    "# Config-1: Split 50:50\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# ==========================================\n",
    "# 2. VARIABEL EKSPERIMEN (SGD)\n",
    "# ==========================================\n",
    "# List LR sama dengan eksperimen sebelumnya\n",
    "list_lr = [0.04, 0.08, 0.06, 0.005, 0.009, 0.007, 0.2, 0.6, 0.012, 0.010, 0.015, 0.018, 0.0111]\n",
    "list_activation = ['logistic', 'relu', 'tanh']\n",
    "list_architecture = [(100, 50), (32, 64, 16), (128, 64, 32, 16), (256, 128, 64, 32, 16)]\n",
    "\n",
    "results = []\n",
    "counter = 1\n",
    "total_exp = len(list_lr) * len(list_activation) * len(list_architecture)\n",
    "\n",
    "print(f\"ðŸš€ MEMULAI {total_exp} EKSPERIMEN SGD (FULL METRICS)...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ==========================================\n",
    "# 3. TRIPLE LOOPING\n",
    "# ==========================================\n",
    "for arch in list_architecture:\n",
    "    for act in list_activation:\n",
    "        for LR in list_lr:\n",
    "            \n",
    "            # --- PERUBAHAN UTAMA DISINI ---\n",
    "            mlp = MLPClassifier(\n",
    "                hidden_layer_sizes=arch,\n",
    "                activation=act,\n",
    "                solver='sgd',             \n",
    "                learning_rate_init=LR,\n",
    "                momentum=0.8,            \n",
    "                max_iter=375,             \n",
    "                random_state=52,\n",
    "                early_stopping=True,\n",
    "                validation_fraction=0.1,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Training\n",
    "            # SGD mungkin akan memunculkan Warning \"ConvergenceWarning\" jika LR terlalu kecil/besar\n",
    "            # Itu wajar dalam eksperimen.\n",
    "            mlp.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # Evaluasi\n",
    "            y_train_pred = mlp.predict(X_train_scaled)\n",
    "            mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "            acc_train = accuracy_score(y_train, y_train_pred)\n",
    "            \n",
    "            # Hitung Detail Per Kelas\n",
    "            precision, recall, f1, support = precision_recall_fscore_support(\n",
    "                y_train, y_train_pred, labels=[0, 1, 2], zero_division=0\n",
    "            )\n",
    "            \n",
    "            # Simpan Data\n",
    "            row = {\n",
    "                \"No\": counter,\n",
    "                \"Split\": \"50:50\",\n",
    "                \"Arsitektur\": str(arch),\n",
    "                \"Activation\": act,\n",
    "                \"Learning Rate\": LR,\n",
    "                \"Epoch\": mlp.n_iter_,\n",
    "                \"Loss (MSE)\": round(mse_train, 5),\n",
    "                \"Acc Train\": round(acc_train, 4),\n",
    "                \n",
    "                # --- Detail Metrics ---\n",
    "                \"Train Precision 0\": round(precision[0], 4),\n",
    "                \"Train Precision 1\": round(precision[1], 4),\n",
    "                \"Train Precision 2\": round(precision[2], 4),\n",
    "                \n",
    "                \"Train Recall 0\": round(recall[0], 4),\n",
    "                \"Train Recall 1\": round(recall[1], 4),\n",
    "                \"Train Recall 2\": round(recall[2], 4),\n",
    "                \n",
    "                \"Train F1 0\": round(f1[0], 4),\n",
    "                \"Train F1 1\": round(f1[1], 4),\n",
    "                \"Train F1 2\": round(f1[2], 4),\n",
    "                \n",
    "                \"Support 0\": support[0],\n",
    "                \"Support 1\": support[1],\n",
    "                \"Support 2\": support[2]\n",
    "            }\n",
    "            results.append(row)\n",
    "            print(f\"âœ… Exp {counter}: SGD | {act} | LR {LR} | Acc: {acc_train:.2%}\")\n",
    "            counter += 1\n",
    "\n",
    "# ==========================================\n",
    "# 4. EXPORT (NAMA FILE BEDA)\n",
    "# ==========================================\n",
    "df_results = pd.DataFrame(results)\n",
    "nama_file = \"Hasil_GridSearch_SGD_Lengkap.csv\" # <--- Supaya tidak menimpa file Adam\n",
    "df_results.to_csv(nama_file, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ðŸŽ‰ SELESAI! File tersimpan sebagai: {nama_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d23261",
   "metadata": {},
   "source": [
    "## Pengujian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4157ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PENGUJIAN DETAIL: Config-1 (50:50) ===\n",
      "\n",
      ">>> DATA UNTUK SPREADSHEET:\n",
      "   No Split Data Configuration   MLP Architecture  Learning Rate Solver  Momentum Activation  Loss Test (MSE)  Acc Test  Prec_Class_0  Prec_Class_1  Prec_Class_2  Prec_Avg  Rec_Class_0  Rec_Class_1  Rec_Class_2  Rec_Avg  F1_Class_0  F1_Class_1  F1_Class_2  F1_Avg  Supp_Class_0  Supp_Class_1  Supp_Class_2  Supp_Total  Random State  Validation Fraction\n",
      "0   1                    50:50  (128, 64, 32, 16)          0.018    sgd       0.9       relu           0.0144    0.9856        0.9888        0.9791        0.9901    0.9856       0.9909       0.9798       0.9813   0.9856      0.9899      0.9794      0.9857  0.9856        3750.0        2625.0        1125.0      7500.0            52                  0.1\n",
      "\n",
      "[SUKSES] File CSV telah disimpan sebagai: Laporan_Testing_Config1_5050.csv\n",
      "Anda bisa langsung import file ini ke Google Sheet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Pemograman Python\\Pengembangan Model MLP\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report\n",
    "\n",
    "# ==========================================\n",
    "# KONFIGURASI 1: 50:50 (SGD) - LAPORAN DETAIL\n",
    "# ==========================================\n",
    "\n",
    "# 1. LOAD DATA\n",
    "df = pd.read_csv('../data/processed_attrition_data.csv')\n",
    "X = df.drop('Attrition_Risk_Level', axis=1)\n",
    "y = df['Attrition_Risk_Level']\n",
    "\n",
    "# 2. SETTING PARAMETER\n",
    "config = {\n",
    "    'name': 'Config-1 (50:50)',\n",
    "    'test_size': 0.50,\n",
    "    'params': {\n",
    "        'hidden_layer_sizes': (128, 64, 32, 16),\n",
    "        'activation': 'relu',\n",
    "        'solver': 'sgd',\n",
    "        'learning_rate_init': 0.018,\n",
    "        'max_iter': 38,\n",
    "        'random_state': 52 \n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"=== PENGUJIAN DETAIL: {config['name']} ===\")\n",
    "\n",
    "# 3. SPLIT DATA\n",
    "indices = np.arange(len(X))\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, y, indices, test_size=config['test_size'], random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. SCALING\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 5. TRAINING\n",
    "model = MLPClassifier(**config['params'])\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 6. PREDIKSI\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# HITUNG METRIK DETAIL\n",
    "# ---------------------------------------------------------\n",
    "# Gunakan output_dict=True agar bisa diambil angkanya\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Ambil metrik global\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Siapkan Dictionary untuk DataFrame\n",
    "# Kita ambil nilai untuk Class 0, 1, 2 (yang di dataset Anda)\n",
    "# Asumsi di Sheet: '1' -> Class 0, '2' -> Class 1, '3' -> Class 2\n",
    "# Jika urutannya beda, tinggal tukar index keys-nya ('0', '1', '2')\n",
    "\n",
    "laporan_dict = {\n",
    "    'No': [1],\n",
    "    'Split Data Configuration': ['50:50'],\n",
    "    'MLP Architecture': [str(config['params']['hidden_layer_sizes'])],\n",
    "    'Learning Rate': [config['params']['learning_rate_init']],\n",
    "    'Solver': [config['params']['solver']],\n",
    "    'Momentum': [0.9],\n",
    "    'Activation': [config['params']['activation']],\n",
    "    'Loss Test (MSE)': [round(mse, 5)],\n",
    "    'Acc Test': [round(acc, 4)],\n",
    "    \n",
    "    # --- PRECISION (Per Class & Avg) ---\n",
    "    'Prec_Class_0': [round(report['0']['precision'], 4)],\n",
    "    'Prec_Class_1': [round(report['1']['precision'], 4)],\n",
    "    'Prec_Class_2': [round(report['2']['precision'], 4)],\n",
    "    'Prec_Avg':     [round(report['weighted avg']['precision'], 4)],\n",
    "    \n",
    "    # --- RECALL (Per Class & Avg) ---\n",
    "    'Rec_Class_0': [round(report['0']['recall'], 4)],\n",
    "    'Rec_Class_1': [round(report['1']['recall'], 4)],\n",
    "    'Rec_Class_2': [round(report['2']['recall'], 4)],\n",
    "    'Rec_Avg':     [round(report['weighted avg']['recall'], 4)],\n",
    "    \n",
    "    # --- F1 SCORE (Per Class & Avg) ---\n",
    "    'F1_Class_0': [round(report['0']['f1-score'], 4)],\n",
    "    'F1_Class_1': [round(report['1']['f1-score'], 4)],\n",
    "    'F1_Class_2': [round(report['2']['f1-score'], 4)],\n",
    "    'F1_Avg':     [round(report['weighted avg']['f1-score'], 4)],\n",
    "    \n",
    "    # --- SUPPORT (Jumlah Data) ---\n",
    "    'Supp_Class_0': [report['0']['support']],\n",
    "    'Supp_Class_1': [report['1']['support']],\n",
    "    'Supp_Class_2': [report['2']['support']],\n",
    "    'Supp_Total':   [report['macro avg']['support']], # Total Data\n",
    "    \n",
    "    'Random State': [config['params']['random_state']],\n",
    "    'Validation Fraction': [0.1]\n",
    "}\n",
    "\n",
    "# Konversi ke DataFrame\n",
    "df_laporan = pd.DataFrame(laporan_dict)\n",
    "\n",
    "nama_file_csv = 'Laporan_Testing_Config1_5050.csv'\n",
    "df_laporan.to_csv(nama_file_csv, index=False)\n",
    "\n",
    "# Tampilkan Full\n",
    "print(\"\\n>>> DATA UNTUK SPREADSHEET:\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "print(df_laporan)\n",
    "\n",
    "print(f\"\\n[SUKSES] File CSV telah disimpan sebagai: {nama_file_csv}\")\n",
    "print(\"Anda bisa langsung import file ini ke Google Sheet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4c6a350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MEMPROSES DATA FULL: Config-1 (50:50) ===\n",
      "\n",
      ">>> TABEL ANALISIS FULL TERBENTUK\n",
      "Total Baris : 7500\n",
      "Total Salah : 108\n",
      "\n",
      ">>> CONTOH 10 DATA PERTAMA:\n",
      "      Status  Prediksi_MLP  Label_Asli  Confidence  Years_Since_Last_Promotion  Job_Satisfaction  Avg_Monthly_Hours  Years_at_Company  Work_Life_Balance  Monthly_Income  Distance_From_Home_KM  Age\n",
      "3201   Benar             0           0      0.9997                           0                 3              168.4                 0                  2            4900                   12.8   25\n",
      "9819   Benar             1           1      1.0000                           6                 4              198.8                14                  2            8656                   11.6   44\n",
      "14147  Benar             0           0      0.7171                           0                 1              157.8                 0                  3            6244                    2.0   37\n",
      "10229  Benar             1           1      0.9743                           8                 4              199.0                19                  2            7651                    7.4   41\n",
      "7274   Benar             0           0      1.0000                           3                 3              186.0                 3                  4            8003                   14.5   33\n",
      "8053   Benar             0           0      1.0000                           1                 4              161.8                11                  2            6446                   10.8   35\n",
      "6544   Benar             1           1      1.0000                           7                 3              193.9                14                  3           11401                   10.4   36\n",
      "10512  Benar             1           1      1.0000                           4                 2              218.0                 5                  4            9284                    6.4   29\n",
      "1800   Benar             2           2      0.9765                           4                 2              192.8                12                  2            6106                   16.0   38\n",
      "8724   Benar             0           0      1.0000                           1                 3              164.8                 2                  4            5081                   27.9   28\n",
      "\n",
      "[INFO] File lengkap telah disimpan sebagai: 'Analisis_Full_7500_Data_Config1.csv'\n",
      "Silakan buka file tersebut di Excel/Spreadsheet untuk melihat mana atribut yang paling sulit diprediksi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Pemograman Python\\Pengembangan Model MLP\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# KONFIGURASI 1: 50:50 (SGD) - ANALISIS FULL ROW\n",
    "# ==========================================\n",
    "\n",
    "# 1. LOAD DATA\n",
    "df = pd.read_csv('../data/processed_attrition_data.csv')\n",
    "X = df.drop('Attrition_Risk_Level', axis=1)\n",
    "y = df['Attrition_Risk_Level']\n",
    "\n",
    "# 2. SETTING PARAMETER\n",
    "config = {\n",
    "    'name': 'Config-1 (50:50)',\n",
    "    'test_size': 0.50,\n",
    "    'params': {\n",
    "        'hidden_layer_sizes': (128, 64, 32, 16),\n",
    "        'activation': 'relu',\n",
    "        'solver': 'sgd',\n",
    "        'learning_rate_init': 0.018,\n",
    "        'max_iter': 38,\n",
    "        'random_state': 52 \n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"=== MEMPROSES DATA FULL: {config['name']} ===\")\n",
    "\n",
    "# 3. SPLIT DATA (Simpan index untuk melacak data asli)\n",
    "indices = np.arange(len(X))\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, y, indices, test_size=config['test_size'], random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. SCALING\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 5. TRAINING\n",
    "model = MLPClassifier(**config['params'])\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 6. PREDIKSI\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# =========================================================\n",
    "# MEMBUAT TABEL ANALISIS LENGKAP (7500 BARIS)\n",
    "# =========================================================\n",
    "\n",
    "# A. Ambil Data Fitur Asli (X) berdasarkan index data test\n",
    "#    (Kita pakai X asli yang belum di-scale agar angkanya bisa dibaca manusia)\n",
    "df_analisis_full = X.loc[idx_test].copy()\n",
    "\n",
    "# B. Masukkan Kolom Hasil Prediksi & Label Asli\n",
    "df_analisis_full.insert(0, 'Status', np.where(y_test == y_pred, 'Benar', 'SALAH')) # Kolom 1\n",
    "df_analisis_full.insert(1, 'Prediksi_MLP', y_pred)                                   # Kolom 2\n",
    "df_analisis_full.insert(2, 'Label_Asli', y_test.values)                              # Kolom 3\n",
    "\n",
    "# C. Tambahkan Probabilitas/Keyakinan Model (Opsional tapi Sangat Berguna)\n",
    "#    Ini menunjukkan seberapa \"yakin\" model dengan tebakannya (0.0 s/d 1.0)\n",
    "proba = model.predict_proba(X_test_scaled)\n",
    "confidence = np.max(proba, axis=1) # Ambil probabilitas tertinggi\n",
    "df_analisis_full.insert(3, 'Confidence', np.round(confidence, 4))\n",
    "\n",
    "print(f\"\\n>>> TABEL ANALISIS FULL TERBENTUK\")\n",
    "print(f\"Total Baris : {len(df_analisis_full)}\")\n",
    "print(f\"Total Salah : {len(df_analisis_full[df_analisis_full['Status'] == 'SALAH'])}\")\n",
    "\n",
    "print(\"\\n>>> CONTOH 10 DATA PERTAMA:\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "print(df_analisis_full.head(10))\n",
    "\n",
    "# D. EXPORT KE CSV (Sangat Disarankan)\n",
    "#    Karena datanya 7500 baris, mustahil dibaca di terminal.\n",
    "#    Save ini lalu buka di Excel/Google Sheets untuk filter kolom 'Status' -> 'SALAH'\n",
    "nama_file = 'Analisis_Full_7500_Data_Config1.csv'\n",
    "df_analisis_full.to_csv(nama_file)\n",
    "print(f\"\\n[INFO] File lengkap telah disimpan sebagai: '{nama_file}'\")\n",
    "print(\"Silakan buka file tersebut di Excel/Spreadsheet untuk melihat mana atribut yang paling sulit diprediksi.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
