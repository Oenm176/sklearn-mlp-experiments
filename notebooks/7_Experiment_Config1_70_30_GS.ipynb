{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9850650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e1bc97",
   "metadata": {},
   "source": [
    "## Adam Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4deb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading Data...\n",
      "‚öôÔ∏è Setting Split Data ke 70:30 (Test Size = 0.3)...\n",
      "üöÄ MEMULAI 156 KOMBINASI EKSPERIMEN (CONFIG 3: 70:30)...\n",
      "============================================================\n",
      "‚úÖ Exp 1: logistic | LR 0.04 | Acc: 99.32%\n",
      "‚úÖ Exp 2: logistic | LR 0.08 | Acc: 98.96%\n",
      "‚úÖ Exp 3: logistic | LR 0.06 | Acc: 99.01%\n",
      "‚úÖ Exp 4: logistic | LR 0.005 | Acc: 98.86%\n",
      "‚úÖ Exp 5: logistic | LR 0.009 | Acc: 99.25%\n",
      "‚úÖ Exp 6: logistic | LR 0.007 | Acc: 99.33%\n",
      "‚úÖ Exp 7: logistic | LR 0.2 | Acc: 98.16%\n",
      "‚úÖ Exp 8: logistic | LR 0.6 | Acc: 92.11%\n",
      "‚úÖ Exp 9: logistic | LR 0.012 | Acc: 99.45%\n",
      "‚úÖ Exp 10: logistic | LR 0.01 | Acc: 99.44%\n",
      "‚úÖ Exp 11: logistic | LR 0.015 | Acc: 99.44%\n",
      "‚úÖ Exp 12: logistic | LR 0.018 | Acc: 98.94%\n",
      "‚úÖ Exp 13: logistic | LR 0.0111 | Acc: 99.44%\n",
      "‚úÖ Exp 14: relu | LR 0.04 | Acc: 99.05%\n",
      "‚úÖ Exp 15: relu | LR 0.08 | Acc: 99.20%\n",
      "‚úÖ Exp 16: relu | LR 0.06 | Acc: 98.57%\n",
      "‚úÖ Exp 17: relu | LR 0.005 | Acc: 98.89%\n",
      "‚úÖ Exp 18: relu | LR 0.009 | Acc: 98.41%\n",
      "‚úÖ Exp 19: relu | LR 0.007 | Acc: 99.01%\n",
      "‚úÖ Exp 20: relu | LR 0.2 | Acc: 98.50%\n",
      "‚úÖ Exp 21: relu | LR 0.6 | Acc: 86.33%\n",
      "‚úÖ Exp 22: relu | LR 0.012 | Acc: 99.30%\n",
      "‚úÖ Exp 23: relu | LR 0.01 | Acc: 98.90%\n",
      "‚úÖ Exp 24: relu | LR 0.015 | Acc: 99.23%\n",
      "‚úÖ Exp 25: relu | LR 0.018 | Acc: 98.99%\n",
      "‚úÖ Exp 26: relu | LR 0.0111 | Acc: 99.28%\n",
      "‚úÖ Exp 27: tanh | LR 0.04 | Acc: 98.38%\n",
      "‚úÖ Exp 28: tanh | LR 0.08 | Acc: 97.92%\n",
      "‚úÖ Exp 29: tanh | LR 0.06 | Acc: 98.11%\n",
      "‚úÖ Exp 30: tanh | LR 0.005 | Acc: 99.00%\n",
      "‚úÖ Exp 31: tanh | LR 0.009 | Acc: 99.26%\n",
      "‚úÖ Exp 32: tanh | LR 0.007 | Acc: 99.37%\n",
      "‚úÖ Exp 33: tanh | LR 0.2 | Acc: 95.36%\n",
      "‚úÖ Exp 34: tanh | LR 0.6 | Acc: 89.42%\n",
      "‚úÖ Exp 35: tanh | LR 0.012 | Acc: 99.05%\n",
      "‚úÖ Exp 36: tanh | LR 0.01 | Acc: 99.34%\n",
      "‚úÖ Exp 37: tanh | LR 0.015 | Acc: 98.90%\n",
      "‚úÖ Exp 38: tanh | LR 0.018 | Acc: 98.95%\n",
      "‚úÖ Exp 39: tanh | LR 0.0111 | Acc: 99.12%\n",
      "‚úÖ Exp 40: logistic | LR 0.04 | Acc: 98.90%\n",
      "‚úÖ Exp 41: logistic | LR 0.08 | Acc: 98.71%\n",
      "‚úÖ Exp 42: logistic | LR 0.06 | Acc: 98.90%\n",
      "‚úÖ Exp 43: logistic | LR 0.005 | Acc: 99.56%\n",
      "‚úÖ Exp 44: logistic | LR 0.009 | Acc: 99.47%\n",
      "‚úÖ Exp 45: logistic | LR 0.007 | Acc: 99.64%\n",
      "‚úÖ Exp 46: logistic | LR 0.2 | Acc: 50.00%\n",
      "‚úÖ Exp 47: logistic | LR 0.6 | Acc: 50.00%\n",
      "‚úÖ Exp 48: logistic | LR 0.012 | Acc: 99.35%\n",
      "‚úÖ Exp 49: logistic | LR 0.01 | Acc: 99.49%\n",
      "‚úÖ Exp 50: logistic | LR 0.015 | Acc: 99.54%\n",
      "‚úÖ Exp 51: logistic | LR 0.018 | Acc: 99.07%\n",
      "‚úÖ Exp 52: logistic | LR 0.0111 | Acc: 99.40%\n",
      "‚úÖ Exp 53: relu | LR 0.04 | Acc: 99.39%\n",
      "‚úÖ Exp 54: relu | LR 0.08 | Acc: 99.04%\n",
      "‚úÖ Exp 55: relu | LR 0.06 | Acc: 99.01%\n",
      "‚úÖ Exp 56: relu | LR 0.005 | Acc: 99.19%\n",
      "‚úÖ Exp 57: relu | LR 0.009 | Acc: 99.10%\n",
      "‚úÖ Exp 58: relu | LR 0.007 | Acc: 98.84%\n",
      "‚úÖ Exp 59: relu | LR 0.2 | Acc: 98.87%\n",
      "‚úÖ Exp 60: relu | LR 0.6 | Acc: 50.00%\n",
      "‚úÖ Exp 61: relu | LR 0.012 | Acc: 98.88%\n",
      "‚úÖ Exp 62: relu | LR 0.01 | Acc: 98.98%\n",
      "‚úÖ Exp 63: relu | LR 0.015 | Acc: 99.21%\n",
      "‚úÖ Exp 64: relu | LR 0.018 | Acc: 99.50%\n",
      "‚úÖ Exp 65: relu | LR 0.0111 | Acc: 98.94%\n",
      "‚úÖ Exp 66: tanh | LR 0.04 | Acc: 98.36%\n",
      "‚úÖ Exp 67: tanh | LR 0.08 | Acc: 97.81%\n",
      "‚úÖ Exp 68: tanh | LR 0.06 | Acc: 98.62%\n",
      "‚úÖ Exp 69: tanh | LR 0.005 | Acc: 99.08%\n",
      "‚úÖ Exp 70: tanh | LR 0.009 | Acc: 99.34%\n",
      "‚úÖ Exp 71: tanh | LR 0.007 | Acc: 98.87%\n",
      "‚úÖ Exp 72: tanh | LR 0.2 | Acc: 92.52%\n",
      "‚úÖ Exp 73: tanh | LR 0.6 | Acc: 82.76%\n",
      "‚úÖ Exp 74: tanh | LR 0.012 | Acc: 99.36%\n",
      "‚úÖ Exp 75: tanh | LR 0.01 | Acc: 99.18%\n",
      "‚úÖ Exp 76: tanh | LR 0.015 | Acc: 99.74%\n",
      "‚úÖ Exp 77: tanh | LR 0.018 | Acc: 99.30%\n",
      "‚úÖ Exp 78: tanh | LR 0.0111 | Acc: 98.65%\n",
      "‚úÖ Exp 79: logistic | LR 0.04 | Acc: 98.42%\n",
      "‚úÖ Exp 80: logistic | LR 0.08 | Acc: 97.13%\n",
      "‚úÖ Exp 81: logistic | LR 0.06 | Acc: 99.21%\n",
      "‚úÖ Exp 82: logistic | LR 0.005 | Acc: 99.04%\n",
      "‚úÖ Exp 83: logistic | LR 0.009 | Acc: 99.36%\n",
      "‚úÖ Exp 84: logistic | LR 0.007 | Acc: 99.21%\n",
      "‚úÖ Exp 85: logistic | LR 0.2 | Acc: 50.00%\n",
      "‚úÖ Exp 86: logistic | LR 0.6 | Acc: 50.00%\n",
      "‚úÖ Exp 87: logistic | LR 0.012 | Acc: 98.62%\n",
      "‚úÖ Exp 88: logistic | LR 0.01 | Acc: 99.27%\n",
      "‚úÖ Exp 89: logistic | LR 0.015 | Acc: 98.86%\n",
      "‚úÖ Exp 90: logistic | LR 0.018 | Acc: 99.13%\n",
      "‚úÖ Exp 91: logistic | LR 0.0111 | Acc: 99.14%\n",
      "‚úÖ Exp 92: relu | LR 0.04 | Acc: 99.31%\n",
      "‚úÖ Exp 93: relu | LR 0.08 | Acc: 99.23%\n",
      "‚úÖ Exp 94: relu | LR 0.06 | Acc: 99.27%\n",
      "‚úÖ Exp 95: relu | LR 0.005 | Acc: 99.20%\n",
      "‚úÖ Exp 96: relu | LR 0.009 | Acc: 98.76%\n",
      "‚úÖ Exp 97: relu | LR 0.007 | Acc: 99.12%\n",
      "‚úÖ Exp 98: relu | LR 0.2 | Acc: 82.94%\n",
      "‚úÖ Exp 99: relu | LR 0.6 | Acc: 50.00%\n",
      "‚úÖ Exp 100: relu | LR 0.012 | Acc: 99.32%\n",
      "‚úÖ Exp 101: relu | LR 0.01 | Acc: 99.50%\n",
      "‚úÖ Exp 102: relu | LR 0.015 | Acc: 99.44%\n",
      "‚úÖ Exp 103: relu | LR 0.018 | Acc: 99.09%\n",
      "‚úÖ Exp 104: relu | LR 0.0111 | Acc: 99.06%\n",
      "‚úÖ Exp 105: tanh | LR 0.04 | Acc: 97.39%\n",
      "‚úÖ Exp 106: tanh | LR 0.08 | Acc: 97.05%\n",
      "‚úÖ Exp 107: tanh | LR 0.06 | Acc: 97.94%\n",
      "‚úÖ Exp 108: tanh | LR 0.005 | Acc: 99.24%\n",
      "‚úÖ Exp 109: tanh | LR 0.009 | Acc: 99.31%\n",
      "‚úÖ Exp 110: tanh | LR 0.007 | Acc: 99.11%\n",
      "‚úÖ Exp 111: tanh | LR 0.2 | Acc: 84.46%\n",
      "‚úÖ Exp 112: tanh | LR 0.6 | Acc: 71.15%\n",
      "‚úÖ Exp 113: tanh | LR 0.012 | Acc: 99.11%\n",
      "‚úÖ Exp 114: tanh | LR 0.01 | Acc: 99.40%\n",
      "‚úÖ Exp 115: tanh | LR 0.015 | Acc: 98.43%\n",
      "‚úÖ Exp 116: tanh | LR 0.018 | Acc: 98.30%\n",
      "‚úÖ Exp 117: tanh | LR 0.0111 | Acc: 98.63%\n",
      "‚úÖ Exp 118: logistic | LR 0.04 | Acc: 98.89%\n",
      "‚úÖ Exp 119: logistic | LR 0.08 | Acc: 95.28%\n",
      "‚úÖ Exp 120: logistic | LR 0.06 | Acc: 50.00%\n",
      "‚úÖ Exp 121: logistic | LR 0.005 | Acc: 99.01%\n",
      "‚úÖ Exp 122: logistic | LR 0.009 | Acc: 99.20%\n",
      "‚úÖ Exp 123: logistic | LR 0.007 | Acc: 99.53%\n",
      "‚úÖ Exp 124: logistic | LR 0.2 | Acc: 50.00%\n",
      "‚úÖ Exp 125: logistic | LR 0.6 | Acc: 50.00%\n",
      "‚úÖ Exp 126: logistic | LR 0.012 | Acc: 99.62%\n",
      "‚úÖ Exp 127: logistic | LR 0.01 | Acc: 99.35%\n",
      "‚úÖ Exp 128: logistic | LR 0.015 | Acc: 99.15%\n",
      "‚úÖ Exp 129: logistic | LR 0.018 | Acc: 99.07%\n",
      "‚úÖ Exp 130: logistic | LR 0.0111 | Acc: 99.46%\n",
      "‚úÖ Exp 131: relu | LR 0.04 | Acc: 99.42%\n",
      "‚úÖ Exp 132: relu | LR 0.08 | Acc: 98.81%\n",
      "‚úÖ Exp 133: relu | LR 0.06 | Acc: 99.24%\n",
      "‚úÖ Exp 134: relu | LR 0.005 | Acc: 99.39%\n",
      "‚úÖ Exp 135: relu | LR 0.009 | Acc: 99.04%\n",
      "‚úÖ Exp 136: relu | LR 0.007 | Acc: 99.10%\n",
      "‚úÖ Exp 137: relu | LR 0.2 | Acc: 50.00%\n",
      "‚úÖ Exp 138: relu | LR 0.6 | Acc: 50.00%\n",
      "‚úÖ Exp 139: relu | LR 0.012 | Acc: 99.44%\n",
      "‚úÖ Exp 140: relu | LR 0.01 | Acc: 98.85%\n",
      "‚úÖ Exp 141: relu | LR 0.015 | Acc: 99.39%\n",
      "‚úÖ Exp 142: relu | LR 0.018 | Acc: 98.75%\n",
      "‚úÖ Exp 143: relu | LR 0.0111 | Acc: 99.08%\n",
      "‚úÖ Exp 144: tanh | LR 0.04 | Acc: 96.87%\n",
      "‚úÖ Exp 145: tanh | LR 0.08 | Acc: 92.53%\n",
      "‚úÖ Exp 146: tanh | LR 0.06 | Acc: 94.40%\n",
      "‚úÖ Exp 147: tanh | LR 0.005 | Acc: 98.48%\n",
      "‚úÖ Exp 148: tanh | LR 0.009 | Acc: 98.30%\n",
      "‚úÖ Exp 149: tanh | LR 0.007 | Acc: 98.27%\n",
      "‚úÖ Exp 150: tanh | LR 0.2 | Acc: 83.19%\n",
      "‚úÖ Exp 151: tanh | LR 0.6 | Acc: 62.44%\n",
      "‚úÖ Exp 152: tanh | LR 0.012 | Acc: 98.81%\n",
      "‚úÖ Exp 153: tanh | LR 0.01 | Acc: 97.70%\n",
      "‚úÖ Exp 154: tanh | LR 0.015 | Acc: 98.39%\n",
      "‚úÖ Exp 155: tanh | LR 0.018 | Acc: 98.11%\n",
      "‚úÖ Exp 156: tanh | LR 0.0111 | Acc: 98.41%\n",
      "\n",
      "============================================================\n",
      "üéâ SELESAI! File tersimpan sebagai: Hasil_GridSearch_Config3_70_30.csv\n",
      "Silakan copy isi file ini ke Sheet Config-3 di Spreadsheet.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. PERSIAPAN DATA (CONFIG 3: 70:30)\n",
    "# ==========================================\n",
    "print(\"üìÇ Loading Data...\")\n",
    "df = pd.read_csv('../data/processed_attrition_data.csv') \n",
    "X = df.drop(columns=['Attrition_Risk_Level'])\n",
    "y = df['Attrition_Risk_Level']\n",
    "\n",
    "# ‚ö†Ô∏è PERUBAHAN DISINI UNTUK CONFIG 3 (70:30)\n",
    "print(\"‚öôÔ∏è Setting Split Data ke 70:30 (Test Size = 0.3)...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y  # <--- GANTI JADI 0.3\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# ==========================================\n",
    "# 2. VARIABEL EKSPERIMEN (GRID SEARCH)\n",
    "# ==========================================\n",
    "list_lr = [0.04, 0.08, 0.06, 0.005, 0.009, 0.007, 0.2, 0.6, 0.012, 0.010, 0.015, 0.018, 0.0111]\n",
    "list_activation = ['logistic', 'relu', 'tanh']\n",
    "list_architecture = [(100, 50), (32, 64, 16), (128, 64, 32, 16), (256, 128, 64, 32, 16)]\n",
    "\n",
    "results = []\n",
    "counter = 1\n",
    "total_exp = len(list_lr) * len(list_activation) * len(list_architecture)\n",
    "\n",
    "print(f\"üöÄ MEMULAI {total_exp} KOMBINASI EKSPERIMEN (CONFIG 3: 70:30)...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ==========================================\n",
    "# 3. TRIPLE LOOPING\n",
    "# ==========================================\n",
    "for arch in list_architecture:\n",
    "    for act in list_activation:\n",
    "        for LR in list_lr:\n",
    "            \n",
    "            # Definisi Model\n",
    "            mlp = MLPClassifier(\n",
    "                hidden_layer_sizes=arch,\n",
    "                activation=act,\n",
    "                solver='sgd',\n",
    "                learning_rate_init=LR,\n",
    "                momentum=0.8,\n",
    "                max_iter=375,\n",
    "                random_state=52,\n",
    "                early_stopping=True,\n",
    "                validation_fraction=0.1,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Training\n",
    "            mlp.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # Evaluasi\n",
    "            y_train_pred = mlp.predict(X_train_scaled)\n",
    "            mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "            acc_train = accuracy_score(y_train, y_train_pred)\n",
    "            \n",
    "            # Hitung Detail Per Kelas\n",
    "            precision, recall, f1, support = precision_recall_fscore_support(\n",
    "                y_train, y_train_pred, labels=[0, 1, 2], zero_division=0\n",
    "            )\n",
    "            \n",
    "            # Simpan Data\n",
    "            row = {\n",
    "                \"No\": counter,\n",
    "                \"Split\": \"70:30\",  # <--- Label diganti jadi 70:30\n",
    "                \"Arsitektur\": str(arch),\n",
    "                \"Activation\": act,\n",
    "                \"Learning Rate\": LR,\n",
    "                \"Epoch\": mlp.n_iter_,\n",
    "                \"Loss (MSE)\": round(mse_train, 5),\n",
    "                \"Acc Train\": round(acc_train, 4),\n",
    "                \n",
    "                # --- Detail Metrics ---\n",
    "                \"Train Precision 0\": round(precision[0], 4),\n",
    "                \"Train Precision 1\": round(precision[1], 4),\n",
    "                \"Train Precision 2\": round(precision[2], 4),\n",
    "                \n",
    "                \"Train Recall 0\": round(recall[0], 4),\n",
    "                \"Train Recall 1\": round(recall[1], 4),\n",
    "                \"Train Recall 2\": round(recall[2], 4),\n",
    "                \n",
    "                \"Train F1 0\": round(f1[0], 4),\n",
    "                \"Train F1 1\": round(f1[1], 4),\n",
    "                \"Train F1 2\": round(f1[2], 4),\n",
    "                \n",
    "                \"Support 0\": support[0],\n",
    "                \"Support 1\": support[1],\n",
    "                \"Support 2\": support[2]\n",
    "            }\n",
    "            results.append(row)\n",
    "            print(f\"‚úÖ Exp {counter}: {act} | LR {LR} | Acc: {acc_train:.2%}\")\n",
    "            counter += 1\n",
    "\n",
    "# ==========================================\n",
    "# 4. EXPORT\n",
    "# ==========================================\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Nama file dibedakan\n",
    "nama_file = \"Hasil_GridSearch_Config3_70_30.csv\" \n",
    "\n",
    "df_results.to_csv(nama_file, index=False)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"üéâ SELESAI! File tersimpan sebagai: {nama_file}\")\n",
    "print(\"Silakan copy isi file ini ke Sheet Config-3 di Spreadsheet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e50ee7",
   "metadata": {},
   "source": [
    "## SGD Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdba6673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading Data...\n",
      "‚öôÔ∏è Setting Split Data ke 70:30 (Test Size = 0.3)...\n",
      "üöÄ MEMULAI 156 KOMBINASI EKSPERIMEN SGD (CONFIG 3: 70:30)...\n",
      "============================================================\n",
      "‚úÖ Exp 1: SGD | logistic | LR 0.04 | Acc: 99.39%\n",
      "‚úÖ Exp 2: SGD | logistic | LR 0.08 | Acc: 99.62%\n",
      "‚úÖ Exp 3: SGD | logistic | LR 0.06 | Acc: 99.40%\n",
      "‚úÖ Exp 4: SGD | logistic | LR 0.005 | Acc: 50.00%\n",
      "‚úÖ Exp 5: SGD | logistic | LR 0.009 | Acc: 50.00%\n",
      "‚úÖ Exp 6: SGD | logistic | LR 0.007 | Acc: 50.00%\n",
      "‚úÖ Exp 7: SGD | logistic | LR 0.2 | Acc: 99.00%\n",
      "‚úÖ Exp 8: SGD | logistic | LR 0.6 | Acc: 98.62%\n",
      "‚úÖ Exp 9: SGD | logistic | LR 0.012 | Acc: 99.10%\n",
      "‚úÖ Exp 10: SGD | logistic | LR 0.01 | Acc: 98.57%\n",
      "‚úÖ Exp 11: SGD | logistic | LR 0.015 | Acc: 99.37%\n",
      "‚úÖ Exp 12: SGD | logistic | LR 0.018 | Acc: 98.90%\n",
      "‚úÖ Exp 13: SGD | logistic | LR 0.0111 | Acc: 99.15%\n",
      "‚úÖ Exp 14: SGD | relu | LR 0.04 | Acc: 99.17%\n",
      "‚úÖ Exp 15: SGD | relu | LR 0.08 | Acc: 99.15%\n",
      "‚úÖ Exp 16: SGD | relu | LR 0.06 | Acc: 99.56%\n",
      "‚úÖ Exp 17: SGD | relu | LR 0.005 | Acc: 99.32%\n",
      "‚úÖ Exp 18: SGD | relu | LR 0.009 | Acc: 99.21%\n",
      "‚úÖ Exp 19: SGD | relu | LR 0.007 | Acc: 99.34%\n",
      "‚úÖ Exp 20: SGD | relu | LR 0.2 | Acc: 98.95%\n",
      "‚úÖ Exp 21: SGD | relu | LR 0.6 | Acc: 99.16%\n",
      "‚úÖ Exp 22: SGD | relu | LR 0.012 | Acc: 99.62%\n",
      "‚úÖ Exp 23: SGD | relu | LR 0.01 | Acc: 99.51%\n",
      "‚úÖ Exp 24: SGD | relu | LR 0.015 | Acc: 99.68%\n",
      "‚úÖ Exp 25: SGD | relu | LR 0.018 | Acc: 99.29%\n",
      "‚úÖ Exp 26: SGD | relu | LR 0.0111 | Acc: 99.56%\n",
      "‚úÖ Exp 27: SGD | tanh | LR 0.04 | Acc: 99.31%\n",
      "‚úÖ Exp 28: SGD | tanh | LR 0.08 | Acc: 98.99%\n",
      "‚úÖ Exp 29: SGD | tanh | LR 0.06 | Acc: 99.29%\n",
      "‚úÖ Exp 30: SGD | tanh | LR 0.005 | Acc: 99.38%\n",
      "‚úÖ Exp 31: SGD | tanh | LR 0.009 | Acc: 99.36%\n",
      "‚úÖ Exp 32: SGD | tanh | LR 0.007 | Acc: 99.46%\n",
      "‚úÖ Exp 33: SGD | tanh | LR 0.2 | Acc: 99.27%\n",
      "‚úÖ Exp 34: SGD | tanh | LR 0.6 | Acc: 98.46%\n",
      "‚úÖ Exp 35: SGD | tanh | LR 0.012 | Acc: 99.44%\n",
      "‚úÖ Exp 36: SGD | tanh | LR 0.01 | Acc: 99.38%\n",
      "‚úÖ Exp 37: SGD | tanh | LR 0.015 | Acc: 99.24%\n",
      "‚úÖ Exp 38: SGD | tanh | LR 0.018 | Acc: 99.25%\n",
      "‚úÖ Exp 39: SGD | tanh | LR 0.0111 | Acc: 99.40%\n",
      "‚úÖ Exp 40: SGD | logistic | LR 0.04 | Acc: 50.00%\n",
      "‚úÖ Exp 41: SGD | logistic | LR 0.08 | Acc: 99.17%\n",
      "‚úÖ Exp 42: SGD | logistic | LR 0.06 | Acc: 99.28%\n",
      "‚úÖ Exp 43: SGD | logistic | LR 0.005 | Acc: 50.00%\n",
      "‚úÖ Exp 44: SGD | logistic | LR 0.009 | Acc: 50.00%\n",
      "‚úÖ Exp 45: SGD | logistic | LR 0.007 | Acc: 50.00%\n",
      "‚úÖ Exp 46: SGD | logistic | LR 0.2 | Acc: 99.38%\n",
      "‚úÖ Exp 47: SGD | logistic | LR 0.6 | Acc: 99.09%\n",
      "‚úÖ Exp 48: SGD | logistic | LR 0.012 | Acc: 50.00%\n",
      "‚úÖ Exp 49: SGD | logistic | LR 0.01 | Acc: 50.00%\n",
      "‚úÖ Exp 50: SGD | logistic | LR 0.015 | Acc: 50.00%\n",
      "‚úÖ Exp 51: SGD | logistic | LR 0.018 | Acc: 50.00%\n",
      "‚úÖ Exp 52: SGD | logistic | LR 0.0111 | Acc: 50.00%\n",
      "‚úÖ Exp 53: SGD | relu | LR 0.04 | Acc: 99.30%\n",
      "‚úÖ Exp 54: SGD | relu | LR 0.08 | Acc: 99.49%\n",
      "‚úÖ Exp 55: SGD | relu | LR 0.06 | Acc: 99.48%\n",
      "‚úÖ Exp 56: SGD | relu | LR 0.005 | Acc: 98.80%\n",
      "‚úÖ Exp 57: SGD | relu | LR 0.009 | Acc: 99.62%\n",
      "‚úÖ Exp 58: SGD | relu | LR 0.007 | Acc: 99.10%\n",
      "‚úÖ Exp 59: SGD | relu | LR 0.2 | Acc: 98.88%\n",
      "‚úÖ Exp 60: SGD | relu | LR 0.6 | Acc: 99.36%\n",
      "‚úÖ Exp 61: SGD | relu | LR 0.012 | Acc: 99.56%\n",
      "‚úÖ Exp 62: SGD | relu | LR 0.01 | Acc: 99.67%\n",
      "‚úÖ Exp 63: SGD | relu | LR 0.015 | Acc: 99.35%\n",
      "‚úÖ Exp 64: SGD | relu | LR 0.018 | Acc: 99.39%\n",
      "‚úÖ Exp 65: SGD | relu | LR 0.0111 | Acc: 99.43%\n",
      "‚úÖ Exp 66: SGD | tanh | LR 0.04 | Acc: 99.35%\n",
      "‚úÖ Exp 67: SGD | tanh | LR 0.08 | Acc: 99.15%\n",
      "‚úÖ Exp 68: SGD | tanh | LR 0.06 | Acc: 99.05%\n",
      "‚úÖ Exp 69: SGD | tanh | LR 0.005 | Acc: 99.50%\n",
      "‚úÖ Exp 70: SGD | tanh | LR 0.009 | Acc: 99.33%\n",
      "‚úÖ Exp 71: SGD | tanh | LR 0.007 | Acc: 99.60%\n",
      "‚úÖ Exp 72: SGD | tanh | LR 0.2 | Acc: 99.32%\n",
      "‚úÖ Exp 73: SGD | tanh | LR 0.6 | Acc: 98.97%\n",
      "‚úÖ Exp 74: SGD | tanh | LR 0.012 | Acc: 99.57%\n",
      "‚úÖ Exp 75: SGD | tanh | LR 0.01 | Acc: 99.59%\n",
      "‚úÖ Exp 76: SGD | tanh | LR 0.015 | Acc: 99.32%\n",
      "‚úÖ Exp 77: SGD | tanh | LR 0.018 | Acc: 99.12%\n",
      "‚úÖ Exp 78: SGD | tanh | LR 0.0111 | Acc: 99.55%\n",
      "‚úÖ Exp 79: SGD | logistic | LR 0.04 | Acc: 50.00%\n",
      "‚úÖ Exp 80: SGD | logistic | LR 0.08 | Acc: 50.00%\n",
      "‚úÖ Exp 81: SGD | logistic | LR 0.06 | Acc: 50.00%\n",
      "‚úÖ Exp 82: SGD | logistic | LR 0.005 | Acc: 50.00%\n",
      "‚úÖ Exp 83: SGD | logistic | LR 0.009 | Acc: 50.00%\n",
      "‚úÖ Exp 84: SGD | logistic | LR 0.007 | Acc: 50.00%\n",
      "‚úÖ Exp 85: SGD | logistic | LR 0.2 | Acc: 50.00%\n",
      "‚úÖ Exp 86: SGD | logistic | LR 0.6 | Acc: 99.13%\n",
      "‚úÖ Exp 87: SGD | logistic | LR 0.012 | Acc: 50.00%\n",
      "‚úÖ Exp 88: SGD | logistic | LR 0.01 | Acc: 50.00%\n",
      "‚úÖ Exp 89: SGD | logistic | LR 0.015 | Acc: 50.00%\n",
      "‚úÖ Exp 90: SGD | logistic | LR 0.018 | Acc: 50.00%\n",
      "‚úÖ Exp 91: SGD | logistic | LR 0.0111 | Acc: 50.00%\n",
      "‚úÖ Exp 92: SGD | relu | LR 0.04 | Acc: 99.35%\n",
      "‚úÖ Exp 93: SGD | relu | LR 0.08 | Acc: 99.57%\n",
      "‚úÖ Exp 94: SGD | relu | LR 0.06 | Acc: 98.86%\n",
      "‚úÖ Exp 95: SGD | relu | LR 0.005 | Acc: 99.09%\n",
      "‚úÖ Exp 96: SGD | relu | LR 0.009 | Acc: 99.59%\n",
      "‚úÖ Exp 97: SGD | relu | LR 0.007 | Acc: 99.55%\n",
      "‚úÖ Exp 98: SGD | relu | LR 0.2 | Acc: 99.82%\n",
      "‚úÖ Exp 99: SGD | relu | LR 0.6 | Acc: 50.02%\n",
      "‚úÖ Exp 100: SGD | relu | LR 0.012 | Acc: 99.06%\n",
      "‚úÖ Exp 101: SGD | relu | LR 0.01 | Acc: 99.67%\n",
      "‚úÖ Exp 102: SGD | relu | LR 0.015 | Acc: 99.06%\n",
      "‚úÖ Exp 103: SGD | relu | LR 0.018 | Acc: 98.93%\n",
      "‚úÖ Exp 104: SGD | relu | LR 0.0111 | Acc: 98.99%\n",
      "‚úÖ Exp 105: SGD | tanh | LR 0.04 | Acc: 97.77%\n",
      "‚úÖ Exp 106: SGD | tanh | LR 0.08 | Acc: 98.14%\n",
      "‚úÖ Exp 107: SGD | tanh | LR 0.06 | Acc: 97.97%\n",
      "‚úÖ Exp 108: SGD | tanh | LR 0.005 | Acc: 99.44%\n",
      "‚úÖ Exp 109: SGD | tanh | LR 0.009 | Acc: 99.49%\n",
      "‚úÖ Exp 110: SGD | tanh | LR 0.007 | Acc: 99.68%\n",
      "‚úÖ Exp 111: SGD | tanh | LR 0.2 | Acc: 97.99%\n",
      "‚úÖ Exp 112: SGD | tanh | LR 0.6 | Acc: 99.43%\n",
      "‚úÖ Exp 113: SGD | tanh | LR 0.012 | Acc: 99.38%\n",
      "‚úÖ Exp 114: SGD | tanh | LR 0.01 | Acc: 99.52%\n",
      "‚úÖ Exp 115: SGD | tanh | LR 0.015 | Acc: 98.61%\n",
      "‚úÖ Exp 116: SGD | tanh | LR 0.018 | Acc: 98.69%\n",
      "‚úÖ Exp 117: SGD | tanh | LR 0.0111 | Acc: 99.53%\n",
      "‚úÖ Exp 118: SGD | logistic | LR 0.04 | Acc: 50.00%\n",
      "‚úÖ Exp 119: SGD | logistic | LR 0.08 | Acc: 50.00%\n",
      "‚úÖ Exp 120: SGD | logistic | LR 0.06 | Acc: 50.00%\n",
      "‚úÖ Exp 121: SGD | logistic | LR 0.005 | Acc: 50.00%\n",
      "‚úÖ Exp 122: SGD | logistic | LR 0.009 | Acc: 50.00%\n",
      "‚úÖ Exp 123: SGD | logistic | LR 0.007 | Acc: 50.00%\n",
      "‚úÖ Exp 124: SGD | logistic | LR 0.2 | Acc: 50.00%\n",
      "‚úÖ Exp 125: SGD | logistic | LR 0.6 | Acc: 50.00%\n",
      "‚úÖ Exp 126: SGD | logistic | LR 0.012 | Acc: 50.00%\n",
      "‚úÖ Exp 127: SGD | logistic | LR 0.01 | Acc: 50.00%\n",
      "‚úÖ Exp 128: SGD | logistic | LR 0.015 | Acc: 50.00%\n",
      "‚úÖ Exp 129: SGD | logistic | LR 0.018 | Acc: 50.00%\n",
      "‚úÖ Exp 130: SGD | logistic | LR 0.0111 | Acc: 50.00%\n",
      "‚úÖ Exp 131: SGD | relu | LR 0.04 | Acc: 99.39%\n",
      "‚úÖ Exp 132: SGD | relu | LR 0.08 | Acc: 99.36%\n",
      "‚úÖ Exp 133: SGD | relu | LR 0.06 | Acc: 98.67%\n",
      "‚úÖ Exp 134: SGD | relu | LR 0.005 | Acc: 98.97%\n",
      "‚úÖ Exp 135: SGD | relu | LR 0.009 | Acc: 99.40%\n",
      "‚úÖ Exp 136: SGD | relu | LR 0.007 | Acc: 99.31%\n",
      "‚úÖ Exp 137: SGD | relu | LR 0.2 | Acc: 99.32%\n",
      "‚úÖ Exp 138: SGD | relu | LR 0.6 | Acc: 72.53%\n",
      "‚úÖ Exp 139: SGD | relu | LR 0.012 | Acc: 98.99%\n",
      "‚úÖ Exp 140: SGD | relu | LR 0.01 | Acc: 98.88%\n",
      "‚úÖ Exp 141: SGD | relu | LR 0.015 | Acc: 99.39%\n",
      "‚úÖ Exp 142: SGD | relu | LR 0.018 | Acc: 99.65%\n",
      "‚úÖ Exp 143: SGD | relu | LR 0.0111 | Acc: 99.86%\n",
      "‚úÖ Exp 144: SGD | tanh | LR 0.04 | Acc: 98.74%\n",
      "‚úÖ Exp 145: SGD | tanh | LR 0.08 | Acc: 98.86%\n",
      "‚úÖ Exp 146: SGD | tanh | LR 0.06 | Acc: 98.76%\n",
      "‚úÖ Exp 147: SGD | tanh | LR 0.005 | Acc: 99.50%\n",
      "‚úÖ Exp 148: SGD | tanh | LR 0.009 | Acc: 99.73%\n",
      "‚úÖ Exp 149: SGD | tanh | LR 0.007 | Acc: 99.03%\n",
      "‚úÖ Exp 150: SGD | tanh | LR 0.2 | Acc: 98.36%\n",
      "‚úÖ Exp 151: SGD | tanh | LR 0.6 | Acc: 98.54%\n",
      "‚úÖ Exp 152: SGD | tanh | LR 0.012 | Acc: 99.30%\n",
      "‚úÖ Exp 153: SGD | tanh | LR 0.01 | Acc: 99.74%\n",
      "‚úÖ Exp 154: SGD | tanh | LR 0.015 | Acc: 98.84%\n",
      "‚úÖ Exp 155: SGD | tanh | LR 0.018 | Acc: 98.90%\n",
      "‚úÖ Exp 156: SGD | tanh | LR 0.0111 | Acc: 99.32%\n",
      "\n",
      "============================================================\n",
      "üéâ SELESAI! File tersimpan sebagai: Hasil_GridSearch_SGD_7030.csv\n",
      "Silakan copy isi file ini ke bagian bawah Sheet Config-3.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. PERSIAPAN DATA (CONFIG 3: 70:30)\n",
    "# ==========================================\n",
    "print(\"üìÇ Loading Data...\")\n",
    "# Pastikan path '../data/' ini benar sesuai folder laptopmu\n",
    "# Kalau error file not found, ganti jadi 'processed_attrition_data.csv' saja\n",
    "df = pd.read_csv('../data/processed_attrition_data.csv') \n",
    "X = df.drop(columns=['Attrition_Risk_Level'])\n",
    "y = df['Attrition_Risk_Level']\n",
    "\n",
    "# ‚ö†Ô∏è SETTING SPLIT 70:30\n",
    "print(\"‚öôÔ∏è Setting Split Data ke 70:30 (Test Size = 0.3)...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y \n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# ==========================================\n",
    "# 2. VARIABEL EKSPERIMEN (SGD)\n",
    "# ==========================================\n",
    "list_lr = [0.04, 0.08, 0.06, 0.005, 0.009, 0.007, 0.2, 0.6, 0.012, 0.010, 0.015, 0.018, 0.0111]\n",
    "list_activation = ['logistic', 'relu', 'tanh']\n",
    "list_architecture = [(100, 50), (32, 64, 16), (128, 64, 32, 16), (256, 128, 64, 32, 16)]\n",
    "\n",
    "results = []\n",
    "counter = 1\n",
    "total_exp = len(list_lr) * len(list_activation) * len(list_architecture)\n",
    "\n",
    "print(f\"üöÄ MEMULAI {total_exp} KOMBINASI EKSPERIMEN SGD (CONFIG 3: 70:30)...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ==========================================\n",
    "# 3. TRIPLE LOOPING\n",
    "# ==========================================\n",
    "for arch in list_architecture:\n",
    "    for act in list_activation:\n",
    "        for LR in list_lr:\n",
    "            \n",
    "            # Definisi Model SGD\n",
    "            mlp = MLPClassifier(\n",
    "                hidden_layer_sizes=arch,\n",
    "                activation=act,\n",
    "                solver='sgd',             # <--- SGD\n",
    "                learning_rate_init=LR,\n",
    "                momentum=0.8,             # <--- Momentum Aktif\n",
    "                max_iter=375,\n",
    "                random_state=52,\n",
    "                early_stopping=True,\n",
    "                validation_fraction=0.1,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Training\n",
    "            mlp.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # Evaluasi\n",
    "            y_train_pred = mlp.predict(X_train_scaled)\n",
    "            mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "            acc_train = accuracy_score(y_train, y_train_pred)\n",
    "            \n",
    "            # Hitung Detail Per Kelas\n",
    "            precision, recall, f1, support = precision_recall_fscore_support(\n",
    "                y_train, y_train_pred, labels=[0, 1, 2], zero_division=0\n",
    "            )\n",
    "            \n",
    "            # Simpan Data\n",
    "            row = {\n",
    "                \"No\": counter,\n",
    "                \"Split\": \"70:30\",\n",
    "                \"Arsitektur\": str(arch),\n",
    "                \"Activation\": act,\n",
    "                \"Learning Rate\": LR,\n",
    "                \"Epoch\": mlp.n_iter_,\n",
    "                \"Loss (MSE)\": round(mse_train, 5),\n",
    "                \"Acc Train\": round(acc_train, 4),\n",
    "                \n",
    "                # --- Detail Metrics ---\n",
    "                \"Train Precision 0\": round(precision[0], 4),\n",
    "                \"Train Precision 1\": round(precision[1], 4),\n",
    "                \"Train Precision 2\": round(precision[2], 4),\n",
    "                \n",
    "                \"Train Recall 0\": round(recall[0], 4),\n",
    "                \"Train Recall 1\": round(recall[1], 4),\n",
    "                \"Train Recall 2\": round(recall[2], 4),\n",
    "                \n",
    "                \"Train F1 0\": round(f1[0], 4),\n",
    "                \"Train F1 1\": round(f1[1], 4),\n",
    "                \"Train F1 2\": round(f1[2], 4),\n",
    "                \n",
    "                \"Support 0\": support[0],\n",
    "                \"Support 1\": support[1],\n",
    "                \"Support 2\": support[2]\n",
    "            }\n",
    "            results.append(row)\n",
    "            print(f\"‚úÖ Exp {counter}: SGD | {act} | LR {LR} | Acc: {acc_train:.2%}\")\n",
    "            counter += 1\n",
    "\n",
    "# ==========================================\n",
    "# 4. EXPORT\n",
    "# ==========================================\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# ‚ö†Ô∏è NAMA FILE DIBEDAKAN (Kasih label SGD)\n",
    "nama_file = \"Hasil_GridSearch_SGD_7030.csv\" \n",
    "\n",
    "df_results.to_csv(nama_file, index=False)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"üéâ SELESAI! File tersimpan sebagai: {nama_file}\")\n",
    "print(\"Silakan copy isi file ini ke bagian bawah Sheet Config-3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ffffc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PENGUJIAN DETAIL: Config-3 (70:30) ===\n",
      "\n",
      ">>> DATA METRIK (Copy ke Sheet 'Config-3 (70:30) Test'):\n",
      "   No Split Data Configuration        MLP Architecture  Learning Rate Solver  \\\n",
      "0   1                    70:30  (256, 128, 64, 32, 16)         0.1111    sgd   \n",
      "\n",
      "   Momentum Activation  Loss Test (MSE)  Acc Test  Prec_Class_0  Prec_Class_1  \\\n",
      "0       0.9       relu             0.02      0.98        0.9977        0.9661   \n",
      "\n",
      "   Prec_Class_2  Prec_Avg  Rec_Class_0  Rec_Class_1  Rec_Class_2  Rec_Avg  \\\n",
      "0         0.956    0.9804       0.9769       0.9771        0.997     0.98   \n",
      "\n",
      "   F1_Class_0  F1_Class_1  F1_Class_2  F1_Avg  Supp_Class_0  Supp_Class_1  \\\n",
      "0      0.9872      0.9716      0.9761  0.9801        2250.0        1575.0   \n",
      "\n",
      "   Supp_Class_2  Supp_Total  Random State  Validation Fraction  \n",
      "0         675.0      4500.0            52                  0.1  \n",
      "\n",
      ">>> ANALISIS ERROR:\n",
      "Total Data Test : 4500\n",
      "Total Salah     : 90\n",
      "File CSV disimpan : Analisis_Full_4500_Data_Config3.csv\n",
      "\n",
      "Contoh 5 Data Salah (Confidence Tertinggi):\n",
      "      Status  Prediksi_MLP  Label_Asli  Confidence  Avg_Monthly_Hours  \\\n",
      "8120   SALAH             1           0      0.9985              159.1   \n",
      "13979  SALAH             1           0      0.9975              185.4   \n",
      "7166   SALAH             1           0      0.9947              131.5   \n",
      "11564  SALAH             1           0      0.9933              195.6   \n",
      "14147  SALAH             1           0      0.9927              157.8   \n",
      "\n",
      "       Job_Satisfaction  \n",
      "8120                  3  \n",
      "13979                 2  \n",
      "7166                  3  \n",
      "11564                 2  \n",
      "14147                 1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Pemograman Python\\Pengembangan Model MLP\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (18) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report\n",
    "\n",
    "# ==========================================\n",
    "# KONFIGURASI 3: 70:30 (SGD) - FINAL REPORT\n",
    "# ==========================================\n",
    "\n",
    "# 1. LOAD DATA\n",
    "# Pastikan path file sesuai dengan lokasi di laptop Anda\n",
    "try:\n",
    "    df = pd.read_csv('../data/processed_attrition_data.csv')\n",
    "except FileNotFoundError:\n",
    "    df = pd.read_csv('processed_attrition_data.csv') # Fallback jika file di folder yang sama\n",
    "\n",
    "X = df.drop('Attrition_Risk_Level', axis=1)\n",
    "y = df['Attrition_Risk_Level']\n",
    "\n",
    "# 2. SETTING PARAMETER (Sesuai Model Terbaik Config-3)\n",
    "config = {\n",
    "    'name': 'Config-3 (70:30)',\n",
    "    'test_size': 0.30,  # 30% Data Test\n",
    "    'params': {\n",
    "        'hidden_layer_sizes': (256, 128, 64, 32, 16), # Arsitektur 5 Layer\n",
    "        'activation': 'relu',\n",
    "        'solver': 'sgd',          # Solver SGD\n",
    "        'learning_rate_init': 0.1111, # LR Unik Anda\n",
    "        'max_iter': 18,           # Epoch 18\n",
    "        'random_state': 52        # Konsisten dengan spreadsheet\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"=== PENGUJIAN DETAIL: {config['name']} ===\")\n",
    "\n",
    "# 3. SPLIT DATA\n",
    "# random_state=42 pada split agar pembagian data konsisten\n",
    "indices = np.arange(len(X))\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, y, indices, test_size=config['test_size'], random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. SCALING\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 5. TRAINING\n",
    "model = MLPClassifier(**config['params'])\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 6. PREDIKSI\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "proba = model.predict_proba(X_test_scaled) # Untuk Confidence level\n",
    "\n",
    "# =========================================================\n",
    "# BAGIAN A: OUTPUT TABEL METRIK (Untuk Sheet Bagian II)\n",
    "# =========================================================\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "laporan_dict = {\n",
    "    'No': [1],\n",
    "    'Split Data Configuration': ['70:30'],\n",
    "    'MLP Architecture': [str(config['params']['hidden_layer_sizes'])],\n",
    "    'Learning Rate': [config['params']['learning_rate_init']],\n",
    "    'Solver': [config['params']['solver']],\n",
    "    'Momentum': [0.9],\n",
    "    'Activation': [config['params']['activation']],\n",
    "    'Loss Test (MSE)': [round(mse, 5)],\n",
    "    'Acc Test': [round(acc, 4)],\n",
    "    \n",
    "    # --- PRECISION ---\n",
    "    'Prec_Class_0': [round(report['0']['precision'], 4)],\n",
    "    'Prec_Class_1': [round(report['1']['precision'], 4)],\n",
    "    'Prec_Class_2': [round(report['2']['precision'], 4)],\n",
    "    'Prec_Avg':     [round(report['weighted avg']['precision'], 4)],\n",
    "    \n",
    "    # --- RECALL ---\n",
    "    'Rec_Class_0': [round(report['0']['recall'], 4)],\n",
    "    'Rec_Class_1': [round(report['1']['recall'], 4)],\n",
    "    'Rec_Class_2': [round(report['2']['recall'], 4)],\n",
    "    'Rec_Avg':     [round(report['weighted avg']['recall'], 4)],\n",
    "    \n",
    "    # --- F1 SCORE ---\n",
    "    'F1_Class_0': [round(report['0']['f1-score'], 4)],\n",
    "    'F1_Class_1': [round(report['1']['f1-score'], 4)],\n",
    "    'F1_Class_2': [round(report['2']['f1-score'], 4)],\n",
    "    'F1_Avg':     [round(report['weighted avg']['f1-score'], 4)],\n",
    "    \n",
    "    # --- SUPPORT ---\n",
    "    'Supp_Class_0': [report['0']['support']],\n",
    "    'Supp_Class_1': [report['1']['support']],\n",
    "    'Supp_Class_2': [report['2']['support']],\n",
    "    'Supp_Total':   [report['macro avg']['support']],\n",
    "    \n",
    "    'Random State': [config['params']['random_state']],\n",
    "    'Validation Fraction': [0.1]\n",
    "}\n",
    "\n",
    "df_laporan = pd.DataFrame(laporan_dict)\n",
    "\n",
    "print(\"\\n>>> DATA METRIK (Copy ke Sheet 'Config-3 (70:30) Test'):\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(df_laporan)\n",
    "\n",
    "# =========================================================\n",
    "# BAGIAN B: OUTPUT ANALISIS ERROR (Untuk Sheet Bagian III)\n",
    "# =========================================================\n",
    "\n",
    "# Ambil fitur asli data test\n",
    "df_analisis_full = X.loc[idx_test].copy()\n",
    "\n",
    "# Masukkan hasil prediksi\n",
    "df_analisis_full.insert(0, 'Status', np.where(y_test == y_pred, 'Benar', 'SALAH'))\n",
    "df_analisis_full.insert(1, 'Prediksi_MLP', y_pred)\n",
    "df_analisis_full.insert(2, 'Label_Asli', y_test.values)\n",
    "df_analisis_full.insert(3, 'Confidence', np.round(np.max(proba, axis=1), 4))\n",
    "\n",
    "# Simpan ke CSV\n",
    "nama_file_csv = 'Analisis_Full_4500_Data_Config3.csv'\n",
    "df_analisis_full.to_csv(nama_file_csv)\n",
    "\n",
    "print(f\"\\n>>> ANALISIS ERROR:\")\n",
    "print(f\"Total Data Test : {len(y_test)}\")\n",
    "print(f\"Total Salah     : {len(df_analisis_full[df_analisis_full['Status'] == 'SALAH'])}\")\n",
    "print(f\"File CSV disimpan : {nama_file_csv}\")\n",
    "\n",
    "# Tampilkan contoh error dengan confidence tinggi (Overconfident)\n",
    "errors = df_analisis_full[df_analisis_full['Status'] == 'SALAH']\n",
    "if len(errors) > 0:\n",
    "    print(\"\\nContoh 5 Data Salah (Confidence Tertinggi):\")\n",
    "    print(errors.sort_values(by='Confidence', ascending=False).head(5)[['Status', 'Prediksi_MLP', 'Label_Asli', 'Confidence', 'Avg_Monthly_Hours', 'Job_Satisfaction']])\n",
    "else:\n",
    "    print(\"Sempurna! Tidak ada error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "741bf4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PENGUJIAN DETAIL: Config-3 (70:30) ===\n",
      "\n",
      ">>> DATA METRIK (Tersimpan di CSV):\n",
      "   No Split Data Configuration        MLP Architecture  Learning Rate Solver  \\\n",
      "0   1                    70:30  (256, 128, 64, 32, 16)         0.1111    sgd   \n",
      "\n",
      "   Momentum Activation  Loss Test (MSE)  Acc Test  Prec_Class_0  Prec_Class_1  \\\n",
      "0       0.9       relu             0.02      0.98        0.9977        0.9661   \n",
      "\n",
      "   Prec_Class_2  Prec_Avg  Rec_Class_0  Rec_Class_1  Rec_Class_2  Rec_Avg  \\\n",
      "0         0.956    0.9804       0.9769       0.9771        0.997     0.98   \n",
      "\n",
      "   F1_Class_0  F1_Class_1  F1_Class_2  F1_Avg  Supp_Class_0  Supp_Class_1  \\\n",
      "0      0.9872      0.9716      0.9761  0.9801        2250.0        1575.0   \n",
      "\n",
      "   Supp_Class_2  Supp_Total  Random State  Validation Fraction  \n",
      "0         675.0      4500.0            52                  0.1  \n",
      "[INFO] File metrik disimpan: Laporan_Testing_Config3_7030.csv\n",
      "\n",
      ">>> ANALISIS ERROR:\n",
      "Total Data Test : 4500\n",
      "Total Salah     : 90\n",
      "[INFO] File analisis full disimpan: Analisis_Full_4500_Data_Config3.csv\n",
      "\n",
      "Contoh 5 Data Salah (Confidence Tertinggi):\n",
      "      Status  Prediksi_MLP  Label_Asli  Confidence  Avg_Monthly_Hours  \\\n",
      "8120   SALAH             1           0      0.9985              159.1   \n",
      "13979  SALAH             1           0      0.9975              185.4   \n",
      "7166   SALAH             1           0      0.9947              131.5   \n",
      "11564  SALAH             1           0      0.9933              195.6   \n",
      "14147  SALAH             1           0      0.9927              157.8   \n",
      "\n",
      "       Job_Satisfaction  \n",
      "8120                  3  \n",
      "13979                 2  \n",
      "7166                  3  \n",
      "11564                 2  \n",
      "14147                 1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Pemograman Python\\Pengembangan Model MLP\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (18) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report\n",
    "\n",
    "# ==========================================\n",
    "# KONFIGURASI 3: 70:30 (SGD) - FINAL REPORT\n",
    "# ==========================================\n",
    "\n",
    "# 1. LOAD DATA\n",
    "try:\n",
    "    df = pd.read_csv('../data/processed_attrition_data.csv')\n",
    "except FileNotFoundError:\n",
    "    df = pd.read_csv('processed_attrition_data.csv') # Fallback\n",
    "\n",
    "X = df.drop('Attrition_Risk_Level', axis=1)\n",
    "y = df['Attrition_Risk_Level']\n",
    "\n",
    "# 2. SETTING PARAMETER\n",
    "config = {\n",
    "    'name': 'Config-3 (70:30)',\n",
    "    'test_size': 0.30,  # 30% Data Test\n",
    "    'params': {\n",
    "        'hidden_layer_sizes': (256, 128, 64, 32, 16),\n",
    "        'activation': 'relu',\n",
    "        'solver': 'sgd',\n",
    "        'learning_rate_init': 0.1111,\n",
    "        'max_iter': 18,\n",
    "        'random_state': 52 \n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"=== PENGUJIAN DETAIL: {config['name']} ===\")\n",
    "\n",
    "# 3. SPLIT DATA\n",
    "indices = np.arange(len(X))\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, y, indices, test_size=config['test_size'], random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. SCALING\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 5. TRAINING\n",
    "model = MLPClassifier(**config['params'])\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 6. PREDIKSI\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "proba = model.predict_proba(X_test_scaled)\n",
    "\n",
    "# =========================================================\n",
    "# BAGIAN A: OUTPUT TABEL METRIK (Untuk Sheet Bagian II)\n",
    "# =========================================================\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "laporan_dict = {\n",
    "    'No': [1],\n",
    "    'Split Data Configuration': ['70:30'],\n",
    "    'MLP Architecture': [str(config['params']['hidden_layer_sizes'])],\n",
    "    'Learning Rate': [config['params']['learning_rate_init']],\n",
    "    'Solver': [config['params']['solver']],\n",
    "    'Momentum': [0.9],\n",
    "    'Activation': [config['params']['activation']],\n",
    "    'Loss Test (MSE)': [round(mse, 5)],\n",
    "    'Acc Test': [round(acc, 4)],\n",
    "    \n",
    "    # --- PRECISION ---\n",
    "    'Prec_Class_0': [round(report['0']['precision'], 4)],\n",
    "    'Prec_Class_1': [round(report['1']['precision'], 4)],\n",
    "    'Prec_Class_2': [round(report['2']['precision'], 4)],\n",
    "    'Prec_Avg':     [round(report['weighted avg']['precision'], 4)],\n",
    "    \n",
    "    # --- RECALL ---\n",
    "    'Rec_Class_0': [round(report['0']['recall'], 4)],\n",
    "    'Rec_Class_1': [round(report['1']['recall'], 4)],\n",
    "    'Rec_Class_2': [round(report['2']['recall'], 4)],\n",
    "    'Rec_Avg':     [round(report['weighted avg']['recall'], 4)],\n",
    "    \n",
    "    # --- F1 SCORE ---\n",
    "    'F1_Class_0': [round(report['0']['f1-score'], 4)],\n",
    "    'F1_Class_1': [round(report['1']['f1-score'], 4)],\n",
    "    'F1_Class_2': [round(report['2']['f1-score'], 4)],\n",
    "    'F1_Avg':     [round(report['weighted avg']['f1-score'], 4)],\n",
    "    \n",
    "    # --- SUPPORT ---\n",
    "    'Supp_Class_0': [report['0']['support']],\n",
    "    'Supp_Class_1': [report['1']['support']],\n",
    "    'Supp_Class_2': [report['2']['support']],\n",
    "    'Supp_Total':   [report['macro avg']['support']],\n",
    "    \n",
    "    'Random State': [config['params']['random_state']],\n",
    "    'Validation Fraction': [0.1]\n",
    "}\n",
    "\n",
    "df_laporan = pd.DataFrame(laporan_dict)\n",
    "\n",
    "# --- SIMPAN CSV METRIK ---\n",
    "nama_file_metrik = 'Laporan_Testing_Config3_7030.csv'\n",
    "df_laporan.to_csv(nama_file_metrik, index=False)\n",
    "\n",
    "print(\"\\n>>> DATA METRIK (Tersimpan di CSV):\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(df_laporan)\n",
    "print(f\"[INFO] File metrik disimpan: {nama_file_metrik}\")\n",
    "\n",
    "# =========================================================\n",
    "# BAGIAN B: OUTPUT ANALISIS ERROR (Untuk Sheet Bagian III)\n",
    "# =========================================================\n",
    "\n",
    "# Ambil fitur asli data test\n",
    "df_analisis_full = X.loc[idx_test].copy()\n",
    "\n",
    "# Masukkan hasil prediksi\n",
    "df_analisis_full.insert(0, 'Status', np.where(y_test == y_pred, 'Benar', 'SALAH'))\n",
    "df_analisis_full.insert(1, 'Prediksi_MLP', y_pred)\n",
    "df_analisis_full.insert(2, 'Label_Asli', y_test.values)\n",
    "df_analisis_full.insert(3, 'Confidence', np.round(np.max(proba, axis=1), 4))\n",
    "\n",
    "# --- SIMPAN CSV ANALISIS FULL ---\n",
    "nama_file_analisis = 'Analisis_Full_4500_Data_Config3.csv'\n",
    "df_analisis_full.to_csv(nama_file_analisis)\n",
    "\n",
    "print(f\"\\n>>> ANALISIS ERROR:\")\n",
    "print(f\"Total Data Test : {len(y_test)}\")\n",
    "print(f\"Total Salah     : {len(df_analisis_full[df_analisis_full['Status'] == 'SALAH'])}\")\n",
    "print(f\"[INFO] File analisis full disimpan: {nama_file_analisis}\")\n",
    "\n",
    "# Tampilkan contoh error dengan confidence tinggi\n",
    "errors = df_analisis_full[df_analisis_full['Status'] == 'SALAH']\n",
    "if len(errors) > 0:\n",
    "    print(\"\\nContoh 5 Data Salah (Confidence Tertinggi):\")\n",
    "    print(errors.sort_values(by='Confidence', ascending=False).head(5)[['Status', 'Prediksi_MLP', 'Label_Asli', 'Confidence', 'Avg_Monthly_Hours', 'Job_Satisfaction']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
